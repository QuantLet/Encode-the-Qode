{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JZal6ahJZQBU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "QPATH = \"Quantlet/4-qode2desc\"\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.chdir(\n",
    "        f\"/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}\"\n",
    "    )\n",
    "\n",
    "#%%capture\n",
    "#%pip install protobuf==3.20.1\n",
    "if IN_COLAB:\n",
    "    %pip install transformers[torch]\n",
    "    %pip install -q sentencepiece\n",
    "    %pip install datasets==2.13.1\n",
    "    %pip install evaluate\n",
    "    %pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iaAT_m3NaEzp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oRmp1O7SZgaI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import torch, gc\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import importlib\n",
    "import analysis_modules\n",
    "\n",
    "importlib.reload(analysis_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few_shot_CodeTrans_no_context_val_20231104\n",
      "few_shot_CodeTrans_no_context_val_20231104\n",
      "cuda\n",
      "cuda\n",
      "Downloading and preparing dataset json/default to /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-f40c96fb4259060f/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffad64f020d4504ba193ae987e8d161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff38c1a2fd248138ef0289f1f9cd802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dd64f6ebd84d3cbe6140a56ba6c7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-f40c96fb4259060f/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bef73e0ac6432f9644f7be4cecc410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-3e428f2a49cb177b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2c7c3858e14ee7994a1817f4abb134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ab8450de45490792581c5b526205cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-3e428f2a49cb177b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-10d3461098ef8afa.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='154' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 01:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      6.512        0.027        0.006        0.025           0.025   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.003        15.426  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='735' max='735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [735/735 10:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.586100</td>\n",
       "      <td>5.003959</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>14.898400</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.265100</td>\n",
       "      <td>0.429600</td>\n",
       "      <td>3261</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.535000</td>\n",
       "      <td>4.915094</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.211500</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>16.118000</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.319200</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>3544</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.707400</td>\n",
       "      <td>4.992931</td>\n",
       "      <td>0.259300</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>16.973800</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>3908</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.119300</td>\n",
       "      <td>5.014568</td>\n",
       "      <td>0.258900</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>16.616400</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.368600</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>3799</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.748600</td>\n",
       "      <td>5.098373</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>17.741000</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>0.539100</td>\n",
       "      <td>4092</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.481800</td>\n",
       "      <td>5.121419</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>17.026200</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>3933</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.290300</td>\n",
       "      <td>5.147704</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>17.314800</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.413100</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>4029</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>5.183220</td>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>16.950800</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>3858</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.053900</td>\n",
       "      <td>5.160844</td>\n",
       "      <td>0.259700</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>17.226200</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>3902</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.987800</td>\n",
       "      <td>5.228225</td>\n",
       "      <td>0.267100</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.232900</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>3841</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.922600</td>\n",
       "      <td>5.181542</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>17.042600</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.511900</td>\n",
       "      <td>3886</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.875800</td>\n",
       "      <td>5.210833</td>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.229400</td>\n",
       "      <td>0.234600</td>\n",
       "      <td>17.341000</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.386400</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>3891</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.830500</td>\n",
       "      <td>5.171567</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>17.239300</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>3864</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.823200</td>\n",
       "      <td>5.176338</td>\n",
       "      <td>0.267900</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>17.363900</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>3949</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.807500</td>\n",
       "      <td>5.186968</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.235200</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>17.324600</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.519700</td>\n",
       "      <td>3945</td>\n",
       "      <td>7591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      5.187         0.27        0.093        0.235            0.24   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.042        17.325  \n",
      "__________\n",
      "Original: Generates plots of energy consumption/production/both time series of energy consumers/prosumers generated from energy readings in 3-minute intervals.\n",
      "\n",
      "\n",
      "Summary before Tuning: \"\" \"\" \"\" \"\" \"\" \"\" \"\" ) ( \"\" ) ( \"\" \"\" \"\" \"\" \"\" \"\"p046 cons\", \"\" \"\" \"\" \"\" \"\" \"\" png ) \"\"p049 cons\", \"\"p048 cons\",\n",
      "\n",
      "\n",
      "Summary after Tuning: This plots the consumption patterns of all the data and plots the production patterns. The following are presented : a) Plots the consumption patterns of all the data and a ) Plots the exemplary consumption patterns of all the data and a ) Plots the exemplary consumption patterns of all the data with respect to the normals of all the data and a\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Scrape the Etherscan API to get source code of smart contracts given the list of their hashes\n",
      "\n",
      "\n",
      "Summary before Tuning: import os import os. path return temp # return temp # #.path.exists(API Token): # #mkdir\n",
      "\n",
      "\n",
      "Summary after Tuning: This Quantlet runs the program.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'hfhd_dataclean code conducts pre-averaging estimation and match the \t\t\t   price and size intensity in a intermediate interval, solves the\n",
      "\n",
      "\n",
      "Summary before Tuning: (inline)(inline)(inline)<-(, f1<-fn1(data0 time,f1)\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the number of orders in the case of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD, subset of TD\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'hfhd_tvnet code plots the time-varying full-sample\n",
      "\n",
      "\n",
      "Summary before Tuning: # # #(1,125,by=3) # # } } } # # axis(2, pos=0) nr=3; f1=4 # } # #\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the scatterplot matrix of the stock MSFT on 100644\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Obtains estimations of parameters involved in the normal-Laplace contaminations by expectation-maximization  algorithm\n",
      "Gives estimations of VaR and ES by historical simulations, based on the Laplace distribution and mixed model. Shows the tails of log returns of CRIX\n",
      "during 2014.04-2018.01 is heavier than that before, and the approximation based on Laplace at scaled level performs well\n",
      "\n",
      "\n",
      "Summary before Tuning: ) }) }) #) }) #) #) }) #) {)2/sqrt(2))\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the effects of the estimation of the VaR and ES in the case of an in-memory model.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Cumulative return of the different cores with an initial investment of 1 dollar\n",
      "\n",
      "\n",
      "Summary before Tuning: %>% <newline>%,,,,,, \"\" = cumsum(c(1, SP500)])) = cumsum(c(1, NASDAQ)) # \"\"%>%\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the cumulative returns for the Core Date, and plots the plots for the date.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Plots the Correlation of an index, here CORE, against crypto currencies\n",
      "\n",
      "\n",
      "Summary before Tuning: %>% %>% %>% %>%\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the zero-coupon Correlation and asymmetric matrix of the same size with asymmetric matrix of correlations for the 84 sp500 cryptos.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Identifies valid URLs for the articles and downloads and saves the full PDFs of all publications from the CRC 649 website.\n",
      "\n",
      "\n",
      "Summary before Tuning: \"\" \"\" \"\" \"\" totext) }) } \"\"pdf\"\" ) } \"\"pdf\"\") } } } # # #, \"\" \"\" \"\"title\"\", \"\"title\"\", \"\"title\"\", \"\"title\"\", \"\"title\"\", \"\"title\"\", \"\"title\"\", \"\"authors\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Scraps the PD Fs from the Quantlets repository and saves the PDFs to the directory of the Quantlet repository.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: computes the Jaccard, simple matching and Tanimoto proximity coefficients for binary car data\n",
      "\n",
      "\n",
      "Summary before Tuning: # setwd( )\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the jaccard and jaccard function for the binary data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Performs a cluster analysis for the US cereal data from the R-package MASS. On the transformed data will be performed a principal component analysis and a cluster analysis employing Euclidean distance with the Ward linkage algorithm. Plots of principal components and the dendrogram are presented. After extraction of 3 clusters, the principal components with the 3 clusters  are shown\n",
      "\n",
      "\n",
      "Summary before Tuning: \"\"(mASS) # plot(mASS,type= \"\"n\"\") # plot(mASS) #) # plot() # # plot(mASS) # # plot(mASS) # # plot(mASS) #) # plot(mASS) # plot(mASS) # #\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the distances of US cereals to the Netherlands cereal data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Employs the centroid linkage using squared Euclidean distance matrices to perform a cluster analysis on an 8 points example\n",
      "\n",
      "\n",
      "Summary before Tuning: from scipy. cluster import tree #) #) # = 2) # = 2) # = 2) #) # = np.mean(ddd)) # =) #) #) # fig.add subplot(1, 2)\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the diagonal of the Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt Belt\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Employs the centroid linkage using squared Euclidean distance matrices to perform a cluster analysis on an 8 points example\n",
      "\n",
      "\n",
      "Summary before Tuning: # install.packages(car) install.packages(car)\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots an 8 points example for minimum spanning trees \n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a lasso logit regression on the car data.'\n",
      "\n",
      "\n",
      "Summary before Tuning: # load packages # # # # # # # # # # #logistic regression lasso for car data set #,y = as.numeric(carc R78 ) y = as.numeric(carc beta ) #\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the effects of logit regression for the car data set.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Applies the sliced inverse regression algorithm  on car data set  for dimension reduction.'\n",
      "\n",
      "\n",
      "Summary before Tuning: ) setwd( )\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the autocorrelation function of the carc.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a test of independence for French baccalaurent data'\n",
      "\n",
      "\n",
      "Summary before Tuning: b ac. d\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs a CVS for the French Banking Actuaureat\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a test of independence for French baccalaurent data'\n",
      "\n",
      "\n",
      "Summary before Tuning: return 0\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Screenshots are destroyed after the Screenshots are destroyed. The function will return immediately.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Computes boxplots for the mileage of US, Japanese and European company headquarters from car data, respectively. Evidently, for the US the core of observations have lowest values of mileage compared with Japan and the EU. However, the US shows larger variation in the data. All boxplots show rather unsymmetric boxes, the medians  and means  are not overlapping.'\n",
      "\n",
      "\n",
      "Summary before Tuning: setwd( )\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the car data and plots the boxplot of the car data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Computes boxplots for the mileage of US, Japanese and European company headquarters from car data, respectively. Evidently, for the US the core of observations have lowest values of mileage compared with Japan and the EU. However, the US shows larger variation in the data. All boxplots show rather unsymmetric boxes, the medians  and means  are not overlapping.'\n",
      "\n",
      "\n",
      "Summary before Tuning: carc.txt carc.txt carc.txt load data\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes boxplots for car data set\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Computes normalized principal components for US crime data set which consists of the reported number of crimes in the 50 US states in 1985. The crimes were classified according to 7 categories: murder, rape, robbery, assault, burglary, larceny, and auto theft. The data set also contains identification of the resion: Northeast, Midwest, South, West. After scaling the variables, a NPCA is perfomed the reported felonies. A scatterplot of the first two principal components, a screeplot and a plot of the correlations of the first two PCs with the original variables.\n",
      "\n",
      "\n",
      "Summary before Tuning: .dat //.dat //, [3:9] //, [10] = pc,' )\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the first three principal components of the Swiss bank notes data and shows the second one's first three principal components.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Computes normalized principal components for US crime data set which consists of the reported number of crimes in the 50 US states in 1985. The crimes were classified according to 7 categories: murder, rape, robbery, assault, burglary, larceny, and auto theft. The data set also contains identification of the resion: Northeast, Midwest, South, West. After scaling the variables, a NPCA is perfomed the reported felonies. A scatterplot of the first two principal components, a screeplot and a plot of the correlations of the first two PCs with the original variables.\n",
      "\n",
      "\n",
      "Summary before Tuning: # set working directory # # # # # # # # # # # # # # # # # # # # # # #\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the pccrime abundance matrix of the US crime data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "Analysis finished\n",
      "few_shot_CodeTrans_no_context_test_20231104\n",
      "few_shot_CodeTrans_no_context_test_20231104\n",
      "cuda\n",
      "cuda\n",
      "Downloading and preparing dataset json/default to /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-e1587c53fc4b8ea3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835e6983cdc94db5809bd40aa10ef6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a57642bc254efe80b78443b55e0a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bd21a6176f47aa88b67ed6d4af7ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-e1587c53fc4b8ea3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c14cb55240460085beef4896d1c110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-4ba105f8784feb40/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0ecde8bd924cf6b3e1c4614f806d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a8d58724924d959f9a18302a55d2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-4ba105f8784feb40/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-d3012674dd39d016.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 01:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      6.531        0.035        0.004        0.032           0.032   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0        0.0        15.615  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 13:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.182900</td>\n",
       "      <td>4.901777</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>17.342500</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.338800</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>4251</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.253800</td>\n",
       "      <td>4.833090</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>16.969400</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>4173</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.635300</td>\n",
       "      <td>4.795277</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>17.642200</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>4464</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.225000</td>\n",
       "      <td>4.877594</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.115600</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>17.275200</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>4366</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.905600</td>\n",
       "      <td>4.913720</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>17.489300</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>4482</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.671700</td>\n",
       "      <td>4.965797</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>17.617700</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>4458</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.474700</td>\n",
       "      <td>4.960315</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>17.630000</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>4535</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.350100</td>\n",
       "      <td>5.005836</td>\n",
       "      <td>0.288200</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.253200</td>\n",
       "      <td>16.920500</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>4241</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.215300</td>\n",
       "      <td>4.998844</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.247800</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>17.458700</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.368700</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>4431</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.132800</td>\n",
       "      <td>5.048370</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.252400</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>17.844000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.379500</td>\n",
       "      <td>0.507900</td>\n",
       "      <td>4496</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.073900</td>\n",
       "      <td>5.034210</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>17.746200</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>0.501200</td>\n",
       "      <td>4437</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.006800</td>\n",
       "      <td>5.013659</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>17.969400</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>4540</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.970200</td>\n",
       "      <td>5.043465</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>17.789000</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.380300</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>4501</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.943700</td>\n",
       "      <td>5.038495</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>17.740100</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.503100</td>\n",
       "      <td>4453</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.930500</td>\n",
       "      <td>5.034913</td>\n",
       "      <td>0.293800</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.259600</td>\n",
       "      <td>17.571900</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.366900</td>\n",
       "      <td>0.499300</td>\n",
       "      <td>4420</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      5.035        0.294        0.119        0.251            0.26   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.049        17.572  \n",
      "__________\n",
      "Original: Generates plots of total over-/underestimation errors of naive, LASSO, and LSTM models for multiple energy consumer and prosumer data sets.\n",
      "\n",
      "\n",
      "Summary before Tuning: ) # #) # # FUN get Predictions. R # #) # predictions c LASSO = naive\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Analyses time series of each time series of a consumer to determine the effects of a given time series.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'hfhd_marketimpact_diff code plots the static and time-varying\n",
      "\n",
      "\n",
      "Summary before Tuning: , # =, #,(,(y, ny) } }, #,,,, #, #, #, #, #, #, #, \"\"netsize1\", \"\"netsize2\", \"\"netsize3\", \"\"net\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the impact of the Netsize of the US, for the year and the month of the year and the year of the year and the year of the year and the year of the UAE, for the year and the year.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Produces the Ensemble XGB model that creates artificial features during training. Model is tested using real data for Polish companies\n",
      "\n",
      "\n",
      "Summary before Tuning: ']; labels = ['CV1year.csv'];;;;;;); # print(Set); # print(Set);\n",
      "\n",
      "\n",
      "Summary after Tuning: This Quantlet runs the regression on the data, which consists of the autoregressive model, the autoregressive model, and the autoregressive model. The loss of the quadratic model increases with a higher score.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Plots time series graphs of mortality and fertility of Japan and Taiwan based on historical data sets.\n",
      "\n",
      "\n",
      "Summary before Tuning: # # # # #, \"\"forecast\"\") lapply(libraries, function(x) { x.packages(x) }) #, # # \"\"Japanese mortality data\"\"\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the mortality data and the estimated mortality data for the US, Japanese and European stocks data and the estimated mortality data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Analyzes demographic trend  and forecasts mortality and fertility in Japan using Hyndman-Ullah method.\n",
      "\n",
      "\n",
      "Summary before Tuning: # # # # # #plot(japan1) HU method Japan mortality data read data japan1 = read.demogdata() plot #plot(japan1)\"\") plot) plotplot\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Estimates and forecasts of the Japanese mortality data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'performs a PCA and a cluster analysis for 20 randomly chosen bank notes from the swiss bank notes dataset.\n",
      "\n",
      "\n",
      "Summary before Tuning: #,main=\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a cluster analysis on the Swiss bank notes dataset using the Ward algorithm.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'performs a PCA and a cluster analysis for 20 randomly chosen bank notes from the swiss bank notes dataset.\n",
      "\n",
      "\n",
      "Summary before Tuning: set global variables set index variable set index variable gca = global; set index variable gca = global;; set(; set\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a cluster analysis for the euclidean distance matrix and a cluster analysis for the euclidean distance matrix.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Tests covariance matrices in Härdle & Simar  Exercise 7.18'\n",
      "\n",
      "\n",
      "Summary before Tuning: disp('CLC') ; } }\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the pool adjacent violator algorithm.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Tests covariance matrices in Härdle & Simar  Exercise 7.18'\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all=TRUE))))\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the optimal value of the chi-square test statistic for the Eye-Hair model.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Provides a profile analysis of citrate concentrations in plasma.'\n",
      "\n",
      "\n",
      "Summary before Tuning: ) show(tmp)) print(tmp) print(tmp) print() print(tmp),diff%meanprf\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the quantlet tests of the quantlet models in the case of the quantlet models.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Provides a profile analysis of citrate concentrations in plasma.'\n",
      "\n",
      "\n",
      "Summary before Tuning: ';'; // = [1*ones(1,5))']; //\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the two-dimensional scatterplots of the Gumbel-Hougaard copula for the profile data set. The lines are the sample 0.001, 0.01, 0.05, 0.25, 0.50, 0.75, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Performs a factor analysis on the variables 'Length','Height Left','Height Right','Inner Frame Lower', 'Inner Frame Upper' and 'Diagonal' in the bank data set using iterated principal factors method  with and without manual rotation by an angle of 7*pi/12 counterclockwise. Estimated factor loadings, communalities and specific variances are presented in a table, plots of original and rotated factor loadings are given\n",
      "\n",
      "\n",
      "Summary before Tuning: ,'b:'),'x','y','y','y',';;,,1);1,2,1) correlation matrix,1\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs a factor analysis on the Swiss bank notes data, with correlations of the PFM and the PFM.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Performs a factor analysis on the variables 'Length','Height Left','Height Right','Inner Frame Lower', 'Inner Frame Upper' and 'Diagonal' in the bank data set using iterated principal factors method  with and without manual rotation by an angle of 7*pi/12 counterclockwise. Estimated factor loadings, communalities and specific variances are presented in a table, plots of original and rotated factor loadings are given\n",
      "\n",
      "\n",
      "Summary before Tuning: # # # # # # # # # # # # # #\n",
      "\n",
      "\n",
      "Summary after Tuning: 'performs a factor analysis on the Swiss bank notes.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Compares a lasso shrinkage regression with ridge regression'\n",
      "\n",
      "\n",
      "Summary before Tuning: graphics.off() #,mvrow=c(1,2),mvcol=,mvcol=,= #\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the effects of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the regression of the\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performes a normalized principal component analysis NPCA on the Geopol data set, which contains a comparison of 41 countries according to 10 political and economic parameters. The NPCA is computed without the first variable, size of population. The remaining variables are\n",
      "\n",
      "\n",
      "Summary before Tuning: // set up the plots,'b') // set up the plots; //,2),2)\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the Swiss bank notes and shows the first three principal components in two-dimensional scatterplots. Additionally, a screeplot of the eigenvalues is displayed.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performes a normalized principal component analysis NPCA on the Geopol data set, which contains a comparison of 41 countries according to 10 political and economic parameters. The NPCA is computed without the first variable, size of population. The remaining variables are\n",
      "\n",
      "\n",
      "Summary before Tuning: # set up the plot # # set up the plot () # #,main= \"\"\"\"\"\") # plot(pcgeopol)) # plot(pcgeopol) # # # #)) main=\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the Swiss bank notes and shows the first three principal components in two-dimensional scatterplots. Additionally, a screeplot of the eigenvalues is displayed.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'performs a correspondence analysis for the US crime data, shows the eigenvalues of the singular value decomposition of the chi-matrix,projections on the first 3 axes and absolute contributions. It also displays graphical the factorial decomposition, the regions are selected in 4 groups , Midwest, South and West).'\n",
      "\n",
      "\n",
      "Summary before Tuning: .dat; x = uscrime;; x = uscrime; x = x;;;;; = s(:,1:2);\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs a multidimensional scaling for US crime data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'performs a correspondence analysis for the US crime data, shows the eigenvalues of the singular value decomposition of the chi-matrix,projections on the first 3 axes and absolute contributions. It also displays graphical the factorial decomposition, the regions are selected in 4 groups , Midwest, South and West).'\n",
      "\n",
      "\n",
      "Summary before Tuning: # = x[,3:] = x[,3:] = = v = y = = (y-e) = = v = rz))) # plot(rr)),plot()) # plot\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs a correspondence analysis for the US crime data set.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: ‘Performs a normalized principal component\n",
      "\n",
      "\n",
      "Summary before Tuning: - Quantlet:'',' Bold') load data ;\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the Swedish athletic data set.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: ‘Performs a normalized principal component\n",
      "\n",
      "\n",
      "Summary before Tuning: # set up the GUI # # # # # # # #) setwd( ) setwd( ) setwd( ) setwd( ) setwd( )\"\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the Belgian-speaking quadratic regression of the Swiss bank notes.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "Analysis finished\n",
      "few_shot_CodeT5_no_context_val_20231104\n",
      "few_shot_CodeT5_no_context_val_20231104\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-f40c96fb4259060f/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90831cdd403849838c1228c91cbb7a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-3e428f2a49cb177b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e05df0b8a254c1aa35deae86929bce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5e861ae91c409ea974ce424026ccd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-3e428f2a49cb177b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-68f00d5c2af5829d.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='154' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 01:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      6.154        0.148        0.043        0.128           0.132   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.017         13.58  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='735' max='735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [735/735 10:19, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.495700</td>\n",
       "      <td>4.995734</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>17.898400</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>4132</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.116900</td>\n",
       "      <td>4.984860</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>17.596700</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>3938</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.006000</td>\n",
       "      <td>5.130800</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>17.616400</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>0.512800</td>\n",
       "      <td>3830</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.400300</td>\n",
       "      <td>5.209966</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>17.927900</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>3926</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.052300</td>\n",
       "      <td>5.383873</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>17.377000</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>3895</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.904500</td>\n",
       "      <td>5.255472</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>17.773800</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>4024</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.781100</td>\n",
       "      <td>5.283758</td>\n",
       "      <td>0.253100</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>17.609800</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.539700</td>\n",
       "      <td>4031</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.715400</td>\n",
       "      <td>5.308001</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>17.754100</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.410900</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>3953</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.669300</td>\n",
       "      <td>5.261320</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>17.950800</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>4042</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>5.341737</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>17.298400</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.388700</td>\n",
       "      <td>0.514100</td>\n",
       "      <td>3840</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.609900</td>\n",
       "      <td>5.293907</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>17.403300</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>3856</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.589700</td>\n",
       "      <td>5.300904</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>17.275400</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>3745</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.573200</td>\n",
       "      <td>5.292410</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>17.672100</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.416400</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>3981</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.570100</td>\n",
       "      <td>5.311967</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.228900</td>\n",
       "      <td>17.714800</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>3972</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.561900</td>\n",
       "      <td>5.316997</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.098700</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>17.596700</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>3938</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      5.317        0.259        0.099        0.224           0.229   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0       0.05        17.597  \n",
      "__________\n",
      "Original: Generates plots of energy consumption/production/both time series of energy consumers/prosumers generated from energy readings in 3-minute intervals.\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots time series recorded by energy smart meters and tibbletime.\n",
      "\n",
      "\n",
      "Summary after Tuning: Plot time series for specified consumers with/without continuous dividends.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Scrape the Etherscan API to get source code of smart contracts given the list of their hashes\n",
      "\n",
      "\n",
      "Summary before Tuning: Load all of the data from the API token. txt and the root folder of the quantlet.\n",
      "\n",
      "\n",
      "Summary after Tuning: Scraping and preprocessing of the Ethereum ethereum Ethereum data from a github repository into the root folder of the Quantlet.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'hfhd_dataclean code conducts pre-averaging estimation and match the \t\t\t   price and size intensity in a intermediate interval, solves the\n",
      "\n",
      "\n",
      "Summary before Tuning: This function calculates the number of limit order book within each time interval and adds it to the next time interval.\n",
      "\n",
      "\n",
      "Summary after Tuning: This quantlet includes the code for the RCVJ_Forecasting project. The code needs \"blarg\" to run the program.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'hfhd_tvnet code plots the time-varying full-sample\n",
      "\n",
      "\n",
      "Summary before Tuning: Demonstrates how to plot all non - negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs a PCA for the RCV data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Obtains estimations of parameters involved in the normal-Laplace contaminations by expectation-maximization  algorithm\n",
      "Gives estimations of VaR and ES by historical simulations, based on the Laplace distribution and mixed model. Shows the tails of log returns of CRIX\n",
      "during 2014.04-2018.01 is heavier than that before, and the approximation based on Laplace at scaled level performs well\n",
      "\n",
      "\n",
      "Summary before Tuning: Calls the method Va R and ES with input parameters given by Crix.\n",
      "\n",
      "\n",
      "Summary after Tuning: Compute and plot the Estimation of a Va R and ES with input parameters of the CRIX.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Cumulative return of the different cores with an initial investment of 1 dollar\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots a series of all variables in the system that have a sequence of type unknown in a specific library.\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes a linear regression of the date of the NIKKEI 225 and plots the time series for the NIKKEI 225.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Plots the Correlation of an index, here CORE, against crypto currencies\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots correlation cryptos with core.\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the correlation matrix for the Swiss bank notes and shows the results in a table.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Identifies valid URLs for the articles and downloads and saves the full PDFs of all publications from the CRC 649 website.\n",
      "\n",
      "\n",
      "Summary before Tuning: This script downloads the papers from all valid links and creates the name of the PD Fs.\n",
      "\n",
      "\n",
      "Summary after Tuning: Scrapes the table-info from the CRC 649 page and performs various diagnostic tests on the pdfs.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: computes the Jaccard, simple matching and Tanimoto proximity coefficients for binary car data\n",
      "\n",
      "\n",
      "Summary before Tuning: clear variables and close windows\n",
      "rm\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the similarity matrix for the carmean2 with respect to probability of default and response variable.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Performs a cluster analysis for the US cereal data from the R-package MASS. On the transformed data will be performed a principal component analysis and a cluster analysis employing Euclidean distance with the Ward linkage algorithm. Plots of principal components and the dendrogram are presented. After extraction of 3 clusters, the principal components with the 3 clusters  are shown\n",
      "\n",
      "\n",
      "Summary before Tuning: plots windows of missing cereal data\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs a PCA for the US cereal data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Employs the centroid linkage using squared Euclidean distance matrices to perform a cluster analysis on an 8 points example\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots the missing cluster chains of the n - th cluster.\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the Lasso solution under the least squares solution for the UK 1973 expenditures.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Employs the centroid linkage using squared Euclidean distance matrices to perform a cluster analysis on an 8 points example\n",
      "\n",
      "\n",
      "Summary before Tuning: plot eight points using centroid linkage linkage\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots an 8 points example for minimum spanning trees \n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a lasso logit regression on the car data.'\n",
      "\n",
      "\n",
      "Summary before Tuning: missing values in the car data set\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes a parallel coordinate plot for the car data set for the car data set.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Applies the sliced inverse regression algorithm  on car data set  for dimension reduction.'\n",
      "\n",
      "\n",
      "Summary before Tuning: get the missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing -\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the scatterplot matrix for the car data set\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a test of independence for French baccalaurent data'\n",
      "\n",
      "\n",
      "Summary before Tuning: clear windows and close windows\n",
      "clear\n",
      "\n",
      "\n",
      "Summary after Tuning: Calculates the size of the BAC data and presents the results in a two dimensional scatterplot of the Swiss bank notes data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a test of independence for French baccalaurent data'\n",
      "\n",
      "\n",
      "Summary before Tuning: clear all n - tuple memory and close windows\n",
      "\n",
      "\n",
      "Summary after Tuning: Simulates a clear on loading the memory of a German kernel and then closes the underlying resources.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Computes boxplots for the mileage of US, Japanese and European company headquarters from car data, respectively. Evidently, for the US the core of observations have lowest values of mileage compared with Japan and the EU. However, the US shows larger variation in the data. All boxplots show rather unsymmetric boxes, the medians  and means  are not overlapping.'\n",
      "\n",
      "\n",
      "Summary before Tuning: plot the mean and standard deviation of the missing mileage\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes a linear regression of mileage on headquarters  of the mileage by company headquarters.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Computes boxplots for the mileage of US, Japanese and European company headquarters from car data, respectively. Evidently, for the US the core of observations have lowest values of mileage compared with Japan and the EU. However, the US shows larger variation in the data. All boxplots show rather unsymmetric boxes, the medians  and means  are not overlapping.'\n",
      "\n",
      "\n",
      "Summary before Tuning: find all non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes a linear regression of mileage on weight and distr.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Computes normalized principal components for US crime data set which consists of the reported number of crimes in the 50 US states in 1985. The crimes were classified according to 7 categories: murder, rape, robbery, assault, burglary, larceny, and auto theft. The data set also contains identification of the resion: Northeast, Midwest, South, West. After scaling the variables, a NPCA is perfomed the reported felonies. A scatterplot of the first two principal components, a screeplot and a plot of the correlations of the first two PCs with the original variables.\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots a single node in the workspace that contains all the non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the Swiss bank notes and shows the first three principal components in two-dimensional scatterplots. Additionally, a screeplot of the first three principal components in the case of TD, subset of WIG 20, MST; only nonzero values are displayed.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Computes normalized principal components for US crime data set which consists of the reported number of crimes in the 50 US states in 1985. The crimes were classified according to 7 categories: murder, rape, robbery, assault, burglary, larceny, and auto theft. The data set also contains identification of the resion: Northeast, Midwest, South, West. After scaling the variables, a NPCA is perfomed the reported felonies. A scatterplot of the first two principal components, a screeplot and a plot of the correlations of the first two PCs with the original variables.\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots the non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the Swiss bank notes and shows the first three principal components in two-dimensional scatterplots. Additionally, a screeplot of the eigenvalues is displayed.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "Analysis finished\n",
      "few_shot_CodeT5_no_context_test_20231104\n",
      "few_shot_CodeT5_no_context_test_20231104\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-e1587c53fc4b8ea3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c217d91056453abc60586e90ec7112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-4ba105f8784feb40/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54f32ad85b64cc8913cb05d035cd9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db574b9e19141c8ae3f4fda89a9725d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-4ba105f8784feb40/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-405256338934b768.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      6.236        0.141        0.042        0.123           0.126   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.011        13.881  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 13:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.036800</td>\n",
       "      <td>4.847597</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>18.104000</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.332300</td>\n",
       "      <td>0.475800</td>\n",
       "      <td>4199</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.780400</td>\n",
       "      <td>4.817539</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>18.327200</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.464600</td>\n",
       "      <td>4100</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.938100</td>\n",
       "      <td>4.863218</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>18.507600</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.361300</td>\n",
       "      <td>0.495500</td>\n",
       "      <td>4373</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.436800</td>\n",
       "      <td>5.033069</td>\n",
       "      <td>0.285600</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.254300</td>\n",
       "      <td>18.009200</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>4066</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.118000</td>\n",
       "      <td>5.065937</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.115600</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.251900</td>\n",
       "      <td>18.082600</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.489900</td>\n",
       "      <td>4323</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.945800</td>\n",
       "      <td>5.142400</td>\n",
       "      <td>0.277100</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>17.755400</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>4247</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.837000</td>\n",
       "      <td>5.064888</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.261400</td>\n",
       "      <td>18.214100</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>4176</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.766600</td>\n",
       "      <td>5.075459</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>18.140700</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>4245</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.709100</td>\n",
       "      <td>5.056930</td>\n",
       "      <td>0.288200</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.248800</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>18.021400</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.459500</td>\n",
       "      <td>4055</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.665900</td>\n",
       "      <td>5.059857</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>18.110100</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.333500</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>4206</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.634700</td>\n",
       "      <td>5.051229</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.248800</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>18.290500</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.478000</td>\n",
       "      <td>4218</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.615700</td>\n",
       "      <td>5.042602</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>18.437300</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.348300</td>\n",
       "      <td>0.486700</td>\n",
       "      <td>4295</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.599600</td>\n",
       "      <td>5.060909</td>\n",
       "      <td>0.294700</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>18.061200</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.330500</td>\n",
       "      <td>0.474600</td>\n",
       "      <td>4188</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.587000</td>\n",
       "      <td>5.045428</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.259500</td>\n",
       "      <td>0.270900</td>\n",
       "      <td>18.174300</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.480500</td>\n",
       "      <td>4240</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.579500</td>\n",
       "      <td>5.054738</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>18.116200</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>4216</td>\n",
       "      <td>8825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      5.055        0.299        0.136        0.257           0.268   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.056        18.116  \n",
      "__________\n",
      "Original: Generates plots of total over-/underestimation errors of naive, LASSO, and LSTM models for multiple energy consumer and prosumer data sets.\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots over - and underestimation for each individual dataset.\n",
      "\n",
      "\n",
      "Summary after Tuning: Generates plots of the over-and underestimation and error analysis for the samples from the Frankfurt Stock Exchange, Frankfurt Stock Exchange  and plots the time series of the 20 largest companies at the 80% significance level from the Frankfurt Stock Exchange  and plots the time series of the D\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'hfhd_marketimpact_diff code plots the static and time-varying\n",
      "\n",
      "\n",
      "Summary before Tuning: missing - block - length - non - zero - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series - time - series -\n",
      "\n",
      "\n",
      "Summary after Tuning: Produces plots of the mileage  of US, Japanese and European company data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Produces the Ensemble XGB model that creates artificial features during training. Model is tested using real data for Polish companies\n",
      "\n",
      "\n",
      "Summary before Tuning: import all the missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing - missing\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the CV-Computes the CV-Computes for the Exgb data set.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Plots time series graphs of mortality and fertility of Japan and Taiwan based on historical data sets.\n",
      "\n",
      "\n",
      "Summary before Tuning: plot windows with nagios\n",
      "\n",
      "\n",
      "Summary after Tuning: Analyses the demog data, shows the first two of them.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Analyzes demographic trend  and forecasts mortality and fertility in Japan using Hyndman-Ullah method.\n",
      "\n",
      "\n",
      "Summary before Tuning: HU method for HU analysis\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA and a cluster analysis for the mortality data, shows the first three principal components of the mortality data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'performs a PCA and a cluster analysis for 20 randomly chosen bank notes from the swiss bank notes dataset.\n",
      "\n",
      "\n",
      "Summary before Tuning: plots the non - random number of non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non - random non\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA and a cluster analysis for the Swiss bank notes data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'performs a PCA and a cluster analysis for 20 randomly chosen bank notes from the swiss bank notes dataset.\n",
      "\n",
      "\n",
      "Summary before Tuning: add graphics on cluster analysis with ward algorithm Dendrogram for cluster analysis with ward algorithm Dendrogram for the data points after ward linkage\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA and a cluster analysis for 20 randomly chosen bank notes from the swiss bank notes dataset.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Tests covariance matrices in Härdle & Simar  Exercise 7.18'\n",
      "\n",
      "\n",
      "Summary before Tuning: clear variables and close windows of all missing variables\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes the a-quantile for the A and B-quantile for the A and B-quantile  for the A and B-quantile  for the A and B-quantile  for the PCA.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Tests covariance matrices in Härdle & Simar  Exercise 7.18'\n",
      "\n",
      "\n",
      "Summary before Tuning: clear variables and close windows of unknown variable values\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the ARIMA estimation results for the Bivariate Student t distribution with parameter estimated with Hewlett Packard.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Provides a profile analysis of citrate concentrations in plasma.'\n",
      "\n",
      "\n",
      "Summary before Tuning: find all windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where there are no windows where\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the time series of the Group 1, 2, and 2 principal components and the equality of the two factors of the Poisson process governing the flow of losses.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Provides a profile analysis of citrate concentrations in plasma.'\n",
      "\n",
      "\n",
      "Summary before Tuning: Estimate the non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the PCA and a parallel coordinate plot for the PCA of the standardized Poisson process governing the flow of losses.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Performs a factor analysis on the variables 'Length','Height Left','Height Right','Inner Frame Lower', 'Inner Frame Upper' and 'Diagonal' in the bank data set using iterated principal factors method  with and without manual rotation by an angle of 7*pi/12 counterclockwise. Estimated factor loadings, communalities and specific variances are presented in a table, plots of original and rotated factor loadings are given\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots all non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero\n",
      "\n",
      "\n",
      "Summary after Tuning: 'performs a factor analysis on the Swiss bank notes data.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Performs a factor analysis on the variables 'Length','Height Left','Height Right','Inner Frame Lower', 'Inner Frame Upper' and 'Diagonal' in the bank data set using iterated principal factors method  with and without manual rotation by an angle of 7*pi/12 counterclockwise. Estimated factor loadings, communalities and specific variances are presented in a table, plots of original and rotated factor loadings are given\n",
      "\n",
      "\n",
      "Summary before Tuning: This function is a utility function that calculates the commalties and loadings of the un - rotated loadings in a given workspace.\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a factor analysis on the Swiss bank notes and shows the eigenvalues of the singular value decomposition of the chi-matrix and displays graphically its factorial decomposition.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Compares a lasso shrinkage regression with ridge regression'\n",
      "\n",
      "\n",
      "Summary before Tuning: clear windows and windows - related\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the Lasso-Risk with parameter alpha = 1.5 and a Risk with Burr / Pareto claim amount = 1.5.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performes a normalized principal component analysis NPCA on the Geopol data set, which contains a comparison of 41 countries according to 10 political and economic parameters. The NPCA is computed without the first variable, size of population. The remaining variables are\n",
      "\n",
      "\n",
      "Summary before Tuning: region all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal components of all - principal\n",
      "\n",
      "\n",
      "Summary after Tuning: Computes normalized principal components for geopol data set which consists of the reported number of crimes in the 50 US states in 1985. The crimes were classified according to the 7 categories: murder, rape, robbery, assault, burglary, larceny, and auto theft. The data set also contains identification\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performes a normalized principal component analysis NPCA on the Geopol data set, which contains a comparison of 41 countries according to 10 political and economic parameters. The NPCA is computed without the first variable, size of population. The remaining variables are\n",
      "\n",
      "\n",
      "Summary before Tuning: plot all kernels with a warning on the first and last non - zero variance matrix\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the Geopoletric data, shows the first three principal components in two-dimensional scatterplots. Additionally, a screeplot of the eigenvalues is displayed.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'performs a correspondence analysis for the US crime data, shows the eigenvalues of the singular value decomposition of the chi-matrix,projections on the first 3 axes and absolute contributions. It also displays graphical the factorial decomposition, the regions are selected in 4 groups , Midwest, South and West).'\n",
      "\n",
      "\n",
      "Summary before Tuning: region region region all - windows - related related functions\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a correspondence analysis for the murder, rape, robbery, assault, burglary, larceny, and auto theft. The data contains 20 stocks listet in S&P 500. The links are presented in the order of attachments. The matlab version equires murder.m to run the\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'performs a correspondence analysis for the US crime data, shows the eigenvalues of the singular value decomposition of the chi-matrix,projections on the first 3 axes and absolute contributions. It also displays graphical the factorial decomposition, the regions are selected in 4 groups , Midwest, South and West).'\n",
      "\n",
      "\n",
      "Summary before Tuning: plots all windows missing missing values\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a correspondence analysis for the US crime data set.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: ‘Performs a normalized principal component\n",
      "\n",
      "\n",
      "Summary before Tuning: This function performs a normalized principal component analysis for the athletic data set.\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a normalized principal component analysis for the athletic data set. The data is classified according to the PCA, the first three principal components, the second two principal components with the original variables are shown as results.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: ‘Performs a normalized principal component\n",
      "\n",
      "\n",
      "Summary before Tuning: Plots the non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero non - zero\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the Athletic data from the MASS. On the transformed data will be performed a PCA for the PCA. On the transformed data will be performed a PCA for the PCA. On the transformed data will be performed a PCA for the PCA.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "Analysis finished\n"
     ]
    }
   ],
   "source": [
    "for MODEL in ['CodeTrans','CodeT5']:   \n",
    "    for SAMPLE_MODE in ['val', 'test']:\n",
    "        if SAMPLE_MODE=='test':\n",
    "            train_name = 'fs_full_train'\n",
    "            test_name  = 'test'\n",
    "        elif SAMPLE_MODE=='val':\n",
    "            train_name = 'fs_train'\n",
    "            test_name  = 'val'\n",
    "        else: \n",
    "            print('Only test and val are available. Please change the SAMPLE_MODE')\n",
    "        \n",
    "        analysis_config = {\n",
    "            \"DATE\": \"20231104\",\n",
    "            \"MODE\": \"no_context\",\n",
    "            \"model_name\": MODEL,\n",
    "            \"encoder_max_length\": 512,\n",
    "            \"decoder_max_length\": 75,\n",
    "            \"random_state\": 42,\n",
    "            \"learning_rate\": 5e-4,\n",
    "            \"epochs\": 15,\n",
    "            \"train_batch\": 4,\n",
    "            \"eval_batch\": 4,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.1,\n",
    "            \"logging_stes\": 100,\n",
    "            \"save_total_lim\": 1,\n",
    "            \"save_strategy\": \"steps\",\n",
    "            \"label_smooting\": 0.1,\n",
    "            \"predict_generate\": True,\n",
    "            \"load_best_model_at_end\": False,\n",
    "            \"evaluation_strategy\": \"epoch\",\n",
    "            \"freeze\": True,\n",
    "        }\n",
    "        \n",
    "        analysis_config[\"train_data_path\"] = f\"../../data/preprocessed/Quantlet/{analysis_config['DATE']}/{analysis_config['MODE']}/\"\n",
    "        analysis_config[\"train_data_name\"] = f\"{train_name}_dataset_sample_0.json\"\n",
    "        \n",
    "        analysis_config[\"val_data_path\"] = f\"../../data/preprocessed/Quantlet/{analysis_config['DATE']}/{analysis_config['MODE']}/\"\n",
    "        analysis_config[\"val_data_name\"] = f\"{test_name}_dataset_{analysis_config['DATE']}_sample0.json\"\n",
    "\n",
    "        analysis_config[\"analysis_name\"] = analysis_modules.create_name(analysis_config)\n",
    "        \n",
    "        analysis_config[\"analysis_name\"] =  'few_shot_' + analysis_config[\"analysis_name\"]\n",
    "\n",
    "        print(analysis_config[\"analysis_name\"])\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        trainer = analysis_modules.scs_analyze(**analysis_config)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        logs = analysis_modules.parse_logs(trainer).drop_duplicates()\n",
    "\n",
    "        ANALYSIS_FOLDER=f'reports/analysis_report_{analysis_config[\"analysis_name\"]}'\n",
    "\n",
    "        logs.to_csv(f'{ANALYSIS_FOLDER}/logs.csv', index=False)\n",
    "\n",
    "        print('Analysis finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPZowVhs+ksZzaIPG80pu3+",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "119XCh3Q64Zw4MGlsZQuGrMLS78o5MeWS",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
