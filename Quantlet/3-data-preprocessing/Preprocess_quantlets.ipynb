{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"mount_file_id":"1lM2sDoEx5jeUuR5QcYONErkcXVm-i9K0","authorship_tag":"ABX9TyPJKzHrbj8TEi9PigsHlaGe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["################################################################################\n","# 1. Preparations"],"metadata":{"id":"Jd7S7ZIIS6Fn"}},{"cell_type":"code","source":["%pip install levenshtein"],"metadata":{"id":"QjyD6T4D1XM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g4K0YWK11RjR"},"outputs":[],"source":["QPATH = \"Quantlet/Data_preprocessing\""]},{"cell_type":"code","source":["# PREPARE WORKING DIRECTORY\n","\n","import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","import os\n","if IN_COLAB:\n","  os.chdir(f'/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}')\n","else:\n","  os.chdir('./')\n","\n","sys.path.append('../src')"],"metadata":{"id":"Xz1ksIsd1SYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PACKAGES\n","\n","import pickle\n","import json\n","import re\n","import sys\n","from IPython.display import display\n","\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import nltk\n","nltk.download('punkt')\n","\n","from tqdm import tqdm\n","tqdm.pandas()\n","import preprocessing_utils\n","\n","import importlib\n","importlib.reload(preprocessing_utils)\n","from preprocessing_utils import *\n","\n","from sklearn.model_selection import train_test_split\n","from Levenshtein import distance\n","\n","# SETTINGS\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","pd.set_option('display.max_colwidth', None)"],"metadata":{"id":"TNkVUfU21UsR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Processing"],"metadata":{"id":"46Fkzpboq6sy"}},{"cell_type":"code","source":["with open('../../data/preprocessed/Quantlet/Parsed_Qs_with_code_25062023.pkl', 'rb') as file:\n","  df = pickle.load(file)"],"metadata":{"id":"E-8ZANoE1bRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RS = 42"],"metadata":{"id":"xGutX1P3okqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df[df.metainfo_file!='empty']\n","print(df.shape)"],"metadata":{"id":"ExQ8Heor30tw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Parse metainfo file\n","if 'Keywords' not in df.columns:\n","  meta_info = pd.DataFrame(columns=['Quantlet', 'Description', 'Keywords', 'Other'])\n","\n","  meta_info[['Quantlet', 'Description', 'Keywords', 'Authors', 'Other']] = df.apply(\n","      lambda x: parse_meta(x),\n","      axis='columns',\n","      result_type='expand'\n","      )\n","\n","  for col in meta_info.columns:\n","      meta_info[col] = meta_info[col].astype(str)\n","\n","  df = pd.concat([df, meta_info], axis=1)\n","\n","  del df['metainfo_file']\n","  del df['Other']\n","  del df['script_name']\n","  del df['script_name_no_ext']"],"metadata":{"id":"6iRcIcEg39Ks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['multiple_scripts'] = df['code_script'].apply(lambda x: any(isinstance(i, list) for i in x))\n","df['code_script_joined'] = ''\n","df.loc[df['multiple_scripts']==True, 'code_script_joined'] = df.loc[df['multiple_scripts']==True, 'code_script'].apply(lambda x: [''.join(code_script) for code_script in x])\n","df.loc[df['multiple_scripts']!=True, 'code_script_joined'] = df.loc[df['multiple_scripts']!=True, 'code_script'].apply(lambda x: [''.join(x)])\n","df['scr_n'] = df['code_script_joined'].apply(len)\n","df['description_len'] = df['Description'].apply(len)\n","df['description_n_words'] = df['Description'].apply(lambda x: len(x.split()))\n","df = df.reset_index(drop=True)"],"metadata":{"id":"yx1chITo4y9M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['main_script'] = np.nan\n","df['main_type_script'] = np.nan"],"metadata":{"id":"aI_G9aGQ8bY_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def explode_code_and_lang(df):\n","    new_df = pd.DataFrame()\n","\n","    print(f'Shape before exploding scripts: {df.shape}')\n","\n","    for index, row in tqdm(df.iterrows()):\n","        if row['multiple_scripts']==True:\n","          for i, script in enumerate(row['code_script']):\n","              row['main_script'] = script\n","              row['main_type_script'] = row['type_script'][i]\n","              new_df = new_df.append(row)\n","        else:\n","          new_df = new_df.append(row)\n","\n","    new_df['main_script'] = new_df['main_script'].fillna(new_df['code_script'])\n","    new_df['main_type_script'] = new_df['main_type_script'].fillna(new_df['type_script'])\n","\n","    new_df = new_df.reset_index(drop=True)\n","    print(f'Shape after exploding scripts: {new_df.shape}')\n","    return new_df\n"],"metadata":{"id":"8CYCiWFj75cl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_long = explode_code_and_lang(df)\n","\n","df_long['code_script'] = df_long['main_script'].progress_apply(lambda x: ''.join(x) if len(x)>0 else np.nan)\n","df_long['type_script'] = df_long['main_type_script']\n","\n","del df_long['main_type_script']\n","del df_long['main_script']\n","del df_long['code_script_joined']\n","\n","df_long = df_long[df_long['Description'].notna()]\n","df_long = df_long[df_long['code_script'].notna()]"],"metadata":{"id":"b85fj5AA5Ac6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_docstring_comment_tags_py(string):\n","    result = string.replace('\\r', '')\n","    s_com = re.compile(r\"(#*)(.*)\\n\")\n","    s_m = re.compile(r'(\"\"\"|\\'\\'\\')(.*?)\\1', re.DOTALL)\n","\n","    result = re.sub(s_com, r\"<COMMENT S> \\2 <COMMENT E>\\n\", result, re.DOTALL)\n","    result = re.sub(s_m, r'<DOCSTR START>\\2<DOCSTR END>\\n', result, re.DOTALL)\n","    return result\n","\n","def add_docstring_comment_tags_r(string):\n","    result = string.replace('\\r', '')\n","    s_com = re.compile(r\"(#*)(.*)\\n\")\n","    s_m = re.compile(r\"#'\\n(.*?)\\n#'\", re.DOTALL)\n","\n","    result = re.sub(s_com, r\"<COMMENT S> \\2 <COMMENT E>\\n\", result, re.DOTALL)\n","    result = re.sub(s_m, r'<DOCSTR START>\\1<DOCSTR END>\\n', result, re.DOTALL)\n","    return result\n","\n","def add_docstring_comment_tags_matlab(string):\n","    result = string.replace('\\r', '')\n","    s_com = re.compile(r\"(%*)(.*)\")\n","    s_m = re.compile(r\"%\\{\\n(.*?)\\n%\\}\", re.DOTALL)\n","\n","    result = re.sub(s_com, r\"<COMMENT S> \\2 <COMMENT E>\\n\", result, re.DOTALL)\n","    result = re.sub(s_m, r'<DOCSTR START>\\1<DOCSTR END>\\n', result, re.DOTALL)\n","    return result\n","\n","def add_docstring_comment_tags(string, lang):\n","    if lang=='py':\n","       result = add_docstring_comment_tags_py(string)\n","    elif lang=='m':\n","       result = add_docstring_comment_tags_matlab(string)\n","    elif lang=='r':\n","       result = add_docstring_comment_tags_r(string)\n","    return result"],"metadata":{"id":"FV8j4kW2YbJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_long.loc[df_long['type_script'].apply(lambda x: isinstance(x, list)), 'type_script'] = 'py'\n","df_long.loc[df_long['type_script']=='ipynb', 'type_script'] = 'py'"],"metadata":{"id":"KouzsOuAlGX9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ANALYZE LENGTH OF THE CODE SNIPPET\n","\n","df_long['code_len'] = df_long['code_script'].progress_apply(len)"],"metadata":{"id":"a5kfMIbOIsH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove duplicate lines\n","def remove_dup_lines(row):\n","  cleaned_up = []\n","  codes_list = row.split('\\n')\n","  for cl in codes_list:\n","    if cl in cleaned_up:\n","      continue\n","    else:\n","      cleaned_up.append(cl)\n","\n","  return '\\n'.join(cleaned_up)"],"metadata":{"id":"ZIXdY301Pz3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_long['code_script'] = df_long['code_script'].progress_apply(remove_dup_lines)\n","df_long['new_len'] = df_long['code_script'].progress_apply(len)"],"metadata":{"id":"wTr5ZFiOKEND"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_too_similar_line(row, inf_gain=0.4):\n","    code_splitted = row.split('\\n')\n","    cleaned_up = []\n","    for i, code_line in enumerate(code_splitted):\n","        if i==0:\n","            cleaned_up.append(code_line)\n","        else:\n","            levenshtein_distance = distance(code_line, cleaned_up[-1])\n","            if levenshtein_distance / len(cleaned_up[-1])>=inf_gain:\n","                cleaned_up.append(code_line)\n","    return '\\n'.join(cleaned_up)\n","\n","def remove_too_similar_token(row, inf_gain=0.4):\n","    code_splitted = row.split('\\n')\n","    cleaned_up = []\n","    for i, code_line in enumerate(code_splitted):\n","        tokenized = code_line.split()\n","        new_line = []\n","        for j, token in enumerate(tokenized):\n","            if j==0:\n","                new_line.append(token)\n","            else:\n","                levenshtein_distance = distance(token, new_line[-1])\n","                if levenshtein_distance / len(new_line[-1])>=inf_gain:\n","                    new_line.append(token)\n","        new_line = ' '.join(new_line)\n","        cleaned_up.append(new_line)\n","    return '\\n'.join(cleaned_up)"],"metadata":{"id":"E0ma3Fq30mZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_long['code_script'] = df_long['code_script'].progress_apply(remove_too_similar_line)\n","df_long['new_len'] = df_long['code_script'].progress_apply(len)"],"metadata":{"id":"NAVpsSiG0tiF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_long['code_script'] = df_long['code_script'].progress_apply(remove_too_similar_token)\n","df_long['new_len2'] = df_long['code_script'].progress_apply(len)"],"metadata":{"id":"cCe0lzBz3wtc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cut_300(row):\n","    tokenized = row.split()\n","    return ' '.join(tokenized[:2500])"],"metadata":{"id":"bm0Um-hUAEZc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df_long['code_script'] = df_long['code_script'].progress_apply(cut_300)"],"metadata":{"id":"p3Riugtu_8Ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def greedy_clean(code_snippet):\n","  code_snippet = re.sub('\\W+', ' ', code_snippet).strip()\n","  cleaned_up = [word for word in code_snippet.split() if len(word)>2]\n","  return ' '.join(cleaned_up)"],"metadata":{"id":"gU1mlMwejx4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CLEAN_ALL = True"],"metadata":{"id":"Rpu1Q3ulkNur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if CLEAN_ALL:\n","    df_long['code_script'] = df_long['code_script'].progress_apply(greedy_clean)"],"metadata":{"id":"4RLPYK4zjreu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labelled_qs, test_qs = train_test_split(list(df_long.Quantlet.unique()),\n","                                     test_size=0.1,\n","                                     random_state=RS)\n","train_qs, val_qs = train_test_split(labelled_qs,\n","                      test_size=0.1,\n","                      random_state=RS)\n","\n","\n","train = df_long[df_long['Quantlet'].isin(set(train_qs))]\n","val   = df_long[df_long['Quantlet'].isin(set(val_qs))]\n","test  = df_long[df_long['Quantlet'].isin(set(test_qs))]"],"metadata":{"id":"kB4zEIB9oea_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.to_csv('../../data/preprocessed/Quantlet/train_df_hard_clean.csv', index=False)\n","val.to_csv('../../data/preprocessed/Quantlet/val_df_hard_clean.csv', index=False)\n","test.to_csv('../../data/preprocessed/Quantlet/test_df_hard_clean.csv', index=False)"],"metadata":{"id":"UIINKvxN_0P3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train.shape)\n","print(train['type_script'].value_counts(normalize=True))"],"metadata":{"id":"onf7xxfKoiqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(val.shape)\n","print(val['type_script'].value_counts(normalize=True))"],"metadata":{"id":"aEOYC_qcpFA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test.shape)\n","print(test['type_script'].value_counts(normalize=True))"],"metadata":{"id":"meSl6XNppNJy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv('../../data/preprocessed/Quantlet/train_df_aut.csv')\n","val   = pd.read_csv('../../data/preprocessed/Quantlet/val_df_aut.csv')\n","test  = pd.read_csv('../../data/preprocessed/Quantlet/test_df_aut.csv')"],"metadata":{"id":"V_dm1sSPL-4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["add_repo = False\n","add_aut  = False"],"metadata":{"id":"7U2cnAzuRDp8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FIX NA\n","test.loc[test['Quantlet'].isna(), 'Quantlet'] = 'XFGexp_rtn_SRM_2d_DOENST RUN'\n","train['Authors'] = train['Authors'].fillna('Unknown')\n","val['Authors']   = val['Authors'].fillna('Unknown')\n","test['Authors']  = test['Authors'].fillna('Unknown')"],"metadata":{"id":"JVVXsnA7XB_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if add_repo & add_aut:\n","   train.loc[:,'code_script'] = 'Repo: ' + train['Quantlet'] + ' ; ' + 'Author: ' + train['Authors'] + ' ; '  + train['code_script']\n","   val.loc[:,'code_script']   = 'Repo: ' + val['Quantlet']   + ' ; ' + 'Author: ' + val['Authors']   + ' ; '  + val['code_script']\n","   test.loc[:,'code_script'] = 'Repo: ' + test['Quantlet']  + ' ; ' + 'Author: ' + test['Authors']  + ' ; '  + test['code_script']\n","\n","elif add_repo:\n","   train.loc[:,'code_script'] = 'Repo: ' + train['Quantlet'] + ' ; ' + train['code_script']\n","   val.loc[:,'code_script']   = 'Repo: ' + val['Quantlet'] + ' ; ' + val['code_script']\n","   test.loc[:,'code_script'] = 'Repo: ' + test['Quantlet'] + ' ; ' + test['code_script']\n","\n","elif add_aut:\n","   train.loc[:,'code_script'] = 'Author: ' + train['Authors'] + ' ; ' + train['code_script']\n","   val.loc[:,'code_script']   = 'Author: ' + val['Authors'] + ' ; ' + val['code_script']\n","   test.loc[:,'code_script'] = 'Author: ' + test['Authors'] + ' ; ' + test['code_script']"],"metadata":{"id":"Q1FyNqapMVUl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Save the Data"],"metadata":{"id":"j5ydgVjsq-hH"}},{"cell_type":"code","source":["train_dataset_json = {'version' : '0.6',\n","                     'data' : [{'input_sequence'  : train['code_script'].iloc[i],\n","                                'output_sequence' : train['Description'].iloc[i]} for i in range(train.shape[0])]}\n","val_dataset_json = {'version' : '0.6',\n","                     'data' : [{'input_sequence'  : val['code_script'].iloc[i],\n","                                'output_sequence' : val['Description'].iloc[i]} for i in range(val.shape[0])]}\n","\n","test_dataset_json = {'version' : '0.6',\n","                     'data' : [{'input_sequence'  : test['code_script'].iloc[i],\n","                                'output_sequence' : test['Description'].iloc[i]} for i in range(test.shape[0])]}\n","\n","\n","with open('../../data/preprocessed/Quantlet/train_dataset_hard_clean.json', 'w') as f:\n","    json.dump(train_dataset_json, f)\n","\n","with open('../../data/preprocessed/Quantlet/val_dataset_hard_clean.json', 'w') as f:\n","    json.dump(val_dataset_json, f)\n","\n","with open('../../data/preprocessed/Quantlet/test_dataset_hard_clean.json', 'w') as f:\n","    json.dump(test_dataset_json, f)"],"metadata":{"id":"98-kOFHGpSLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TAr4ucUNXVer"},"execution_count":null,"outputs":[]}]}