{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"mount_file_id":"1lM2sDoEx5jeUuR5QcYONErkcXVm-i9K0","authorship_tag":"ABX9TyMcictFsy/9EgFa1X9aBGwj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["################################################################################\n","# 1. Preparations"],"metadata":{"id":"Jd7S7ZIIS6Fn"}},{"cell_type":"code","source":["%pip install levenshtein"],"metadata":{"id":"QjyD6T4D1XM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g4K0YWK11RjR"},"outputs":[],"source":["QPATH = \"Quantlet/3-data-preprocessing\""]},{"cell_type":"code","source":["# PREPARE WORKING DIRECTORY\n","\n","import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","import os\n","if IN_COLAB:\n","  os.chdir(f'/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}')\n","else:\n","  os.chdir('./')\n","\n","#sys.path.append('../src')"],"metadata":{"id":"Xz1ksIsd1SYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PACKAGES\n","\n","import pickle\n","import json\n","import re\n","import sys\n","from IPython.display import display\n","\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import nltk\n","nltk.download('punkt')\n","\n","from tqdm import tqdm\n","tqdm.pandas()\n","\n","import importlib\n","import preprocessing_utils\n","importlib.reload(preprocessing_utils)\n","from preprocessing_utils import *\n","\n","#import importlib\n","#importlib.reload(preprocessing_utils)\n","#from preprocessing_utils import *\n","\n","from sklearn.model_selection import train_test_split\n","from Levenshtein import distance\n","\n","# SETTINGS\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","pd.set_option('display.max_colwidth', 500)"],"metadata":{"id":"TNkVUfU21UsR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Processing"],"metadata":{"id":"46Fkzpboq6sy"}},{"cell_type":"code","source":["#with open('../../data/preprocessed/Quantlet/Parsed_Qs_with_code_25062023.pkl', 'rb') as file:\n","#  df = pickle.load(file)\n","with open('../../data/preprocessed/Quantlet/Qs_reduced_23092023.pkl', 'rb') as file:\n","  df = pickle.load(file)"],"metadata":{"id":"E-8ZANoE1bRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RS = 42\n","CLEAN_ALL = False"],"metadata":{"id":"xGutX1P3okqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df[df.metainfo_file!='empty']\n","print(df.shape)\n","\n","# Parse metainfo file\n","if 'Keywords' not in df.columns:\n","  meta_info = pd.DataFrame(columns=['Quantlet', 'Description', 'Keywords', 'Other'])\n","\n","  meta_info[['Quantlet', 'Description', 'Keywords', 'Authors', 'Other']] = df.apply(\n","      lambda x: parse_meta(x),\n","      axis='columns',\n","      result_type='expand'\n","      )\n","\n","  for col in meta_info.columns:\n","      meta_info[col] = meta_info[col].astype(str)\n","\n","  df = pd.concat([df, meta_info], axis=1)\n","\n","  del df['metainfo_file']\n","  del df['Other']\n","  del df['script_name_no_ext']"],"metadata":{"id":"6iRcIcEg39Ks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PREPARE THE SCRIPT\n","df['code_script'] = df['code_script'].apply(lambda x: [line for line in x if len(line)>0])\n","df['code_script'] = df['code_script'].apply(lambda x: ' '.join(x))\n"],"metadata":{"id":"cukmnLJ8F5GF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['scr_n'] = df['code_script'].apply(len)\n","df['description_len'] = df['Description'].apply(len)\n","df['description_n_words'] = df['Description'].apply(lambda x: len(x.split()))\n","df = df.reset_index(drop=True)\n","\n","# Reset Index\n","df_long = df.reset_index(drop=True)"],"metadata":{"id":"aI_G9aGQ8bY_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ADD REPO INFORMATION\n","df_long['repo'] = df_long['folder_name'].str.split('QuantLet/', expand=True)[1].str.split('/', expand=True)[0]"],"metadata":{"id":"ddH64easIa7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_long.repo.value_counts()\n","\n","# 4 groups\n","\n","# no neighbors\n","# less than 5 neighbors\n","# between 5 and 10 neighbors\n","# more than 10 neighbors"],"metadata":{"id":"HSsWU3MmGSj9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ANALYZE LENGTH OF THE CODE SNIPPET\n","\n","df_long['code_len'] = df_long['code_script'].progress_apply(len)\n","\n","# REMOVE CODE LINE DUPLICATES\n","df_long['code_script'] = df_long['code_script'].progress_apply(remove_dup_lines)\n","df_long['new_len'] = df_long['code_script'].progress_apply(len)\n","\n","# REMOVE TOO SIMILAR LINES\n","# we want to get as much information\n","df_long['code_script'] = df_long['code_script'].progress_apply(remove_too_similar_line)\n","df_long['new_len'] = df_long['code_script'].progress_apply(len)\n","\n","# REMOVE TOO SIMILAR TOKENS\n","df_long['code_script'] = df_long['code_script'].progress_apply(remove_too_similar_token)\n","df_long['new_len2'] = df_long['code_script'].progress_apply(len)\n","\n","df_long = df_long.reset_index(drop=True)\n","df_long = df_long.drop(list(df_long[df_long['new_len2']==0].index)).reset_index(drop=True)"],"metadata":{"id":"b85fj5AA5Ac6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df_long['code_script'] = df_long['code_script'].progress_apply(cut_300)"],"metadata":{"id":"KouzsOuAlGX9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if CLEAN_ALL:\n","    df_long['code_script'] = df_long['code_script'].progress_apply(greedy_clean)"],"metadata":{"id":"a5kfMIbOIsH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SPLIT THE DATA\n","labelled_qs, test_qs = train_test_split(list(df_long.Quantlet.unique()),\n","                                     test_size=0.1,\n","                                     random_state=RS)\n","train_qs, val_qs = train_test_split(labelled_qs,\n","                      test_size=0.1,\n","                      random_state=RS)\n","\n","\n","train = df_long[df_long['Quantlet'].isin(set(train_qs))].reset_index(drop=True)\n","val   = df_long[df_long['Quantlet'].isin(set(val_qs))].reset_index(drop=True)\n","test  = df_long[df_long['Quantlet'].isin(set(test_qs))].reset_index(drop=True)\n","\n","full_train = pd.concat([train, test], axis=0).sample(frac=1, random_state=RS).reset_index(drop=True)"],"metadata":{"id":"wTr5ZFiOKEND"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_train.to_csv('../../data/preprocessed/Quantlet/full_train_df_20230923.csv', index=False)\n","train.to_csv('../../data/preprocessed/Quantlet/train_df_20230923.csv', index=False)\n","val.to_csv('../../data/preprocessed/Quantlet/val_df_20230923.csv', index=False)\n","test.to_csv('../../data/preprocessed/Quantlet/test_df_20230923.csv', index=False)\n","\n","\n","print(train.shape)\n","print(train['type_script'].value_counts(normalize=True))\n","print(val.shape)\n","print(val['type_script'].value_counts(normalize=True))\n","print(test.shape)\n","print(test['type_script'].value_counts(normalize=True))"],"metadata":{"id":"UIINKvxN_0P3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for MODE in ['no_context', 'author', 'repo', 'both']:\n","    full_train = pd.read_csv('../../data/preprocessed/Quantlet/full_train_df_20230923.csv')\n","    train = pd.read_csv('../../data/preprocessed/Quantlet/train_df_20230923.csv')\n","    val   = pd.read_csv('../../data/preprocessed/Quantlet/val_df_20230923.csv')\n","    test  = pd.read_csv('../../data/preprocessed/Quantlet/test_df_20230923.csv')\n","\n","    # FIX NA\n","    test.loc[test['Quantlet'].isna(), 'Quantlet'] = 'XFGexp_rtn_SRM_2d_DOENST RUN'\n","    train['Authors'] = train['Authors'].fillna('Unknown')\n","    val['Authors']   = val['Authors'].fillna('Unknown')\n","    test['Authors']  = test['Authors'].fillna('Unknown')\n","\n","\n","    if MODE=='both':\n","      train.loc[:,'code_script'] = 'Repo: ' + train['repo'] + ' ; ' + ' ; ' + 'Author: ' + train['Authors'] + ' ; '  + train['code_script']\n","      val.loc[:,'code_script']   = 'Repo: ' + val['repo']   + ' ; ' + ' ; ' + 'Author: ' + val['Authors']   + ' ; '  + val['code_script']\n","      test.loc[:,'code_script'] = 'Repo: ' + test['repo']  + ' ; ' + ' ; ' + 'Author: ' + test['Authors']  + ' ; '  + test['code_script']\n","\n","    elif MODE=='repo':\n","      train.loc[:,'code_script'] = 'Repo: ' + train['repo'] + ' ; ' + train['code_script']\n","      val.loc[:,'code_script']   = 'Repo: ' + val['repo'] + ' ; ' + val['code_script']\n","      test.loc[:,'code_script'] = 'Repo: ' + test['repo'] + ' ; ' + test['code_script']\n","\n","    #elif add_quantlet:\n","    #   train.loc[:,'code_script'] = 'Quantlet: ' + train['Quantlet'] + ' ; ' + train['code_script']\n","    #   val.loc[:,'code_script']   = 'Quantlet: ' + val['Quantlet'] + ' ; ' + val['code_script']\n","    #   test.loc[:,'code_script'] = 'Quantlet: ' + test['Quantlet'] + ' ; ' + test['code_script']\n","\n","    elif MODE=='author':\n","      train.loc[:,'code_script'] = 'Author: ' + train['Authors'] + ' ; ' + train['code_script']\n","      val.loc[:,'code_script']   = 'Author: ' + val['Authors'] + ' ; ' + val['code_script']\n","      test.loc[:,'code_script'] = 'Author: ' + test['Authors'] + ' ; ' + test['code_script']\n","\n","    train_dataset_json = {'version' : '1.0',\n","                        'data' : [{'input_sequence'  : train['code_script'].iloc[i],\n","                                    'output_sequence' : train['Description'].iloc[i]} for i in range(train.shape[0])]}\n","    val_dataset_json = {'version' : '1.0',\n","                        'data' : [{'input_sequence'  : val['code_script'].iloc[i],\n","                                    'output_sequence' : val['Description'].iloc[i]} for i in range(val.shape[0])]}\n","\n","    full_train_dataset_json = {'version' : '1.0',\n","                                'data' : [{'input_sequence'  : full_train['code_script'].iloc[i],\n","                                            'output_sequence' : full_train['Description'].iloc[i]} for i in range(full_train.shape[0])]}\n","\n","    test_dataset_json = {'version' : '1.0',\n","                        'data' : [{'input_sequence'  : test['code_script'].iloc[i],\n","                                    'output_sequence' : test['Description'].iloc[i]} for i in range(test.shape[0])]}\n","\n","\n","    with open(f'../../data/preprocessed/Quantlet/{MODE}/full_train_dataset_20230923.json', 'w') as f:\n","        json.dump(full_train_dataset_json, f)\n","\n","    with open(f'../../data/preprocessed/Quantlet/{MODE}/train_dataset_20230923.json', 'w') as f:\n","        json.dump(train_dataset_json, f)\n","\n","    with open(f'../../data/preprocessed/Quantlet/{MODE}/val_dataset_20230923.json', 'w') as f:\n","        json.dump(val_dataset_json, f)\n","\n","    with open(f'../../data/preprocessed/Quantlet/{MODE}/test_dataset_20230923.json', 'w') as f:\n","        json.dump(test_dataset_json, f)"],"metadata":{"id":"Q1FyNqapMVUl"},"execution_count":null,"outputs":[]}]}