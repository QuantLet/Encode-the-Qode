{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd7S7ZIIS6Fn"
   },
   "source": [
    "################################################################################\n",
    "# 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QjyD6T4D1XM4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g4K0YWK11RjR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "QPATH = \"Quantlet/3-data-preprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xz1ksIsd1SYO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREPARE WORKING DIRECTORY\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.chdir(\n",
    "        f\"/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}\"\n",
    "    )\n",
    "else:\n",
    "    os.chdir(\"./\")\n",
    "\n",
    "# sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TNkVUfU21UsR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# PACKAGES\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import importlib\n",
    "import preprocessing_utils\n",
    "\n",
    "importlib.reload(preprocessing_utils)\n",
    "from preprocessing_utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Levenshtein import distance\n",
    "\n",
    "# SETTINGS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Fkzpboq6sy"
   },
   "source": [
    "# 2. Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATE = \"20231104\"\n",
    "RS = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    f\"../../data/preprocessed/Quantlet/20231027/Quantlets_20231027.pkl\", \"rb\"\n",
    ") as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5018, 6)\n",
      "(5017, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5017/5017 [00:35<00:00, 141.89it/s]\n",
      "100%|██████████| 5017/5017 [00:58<00:00, 86.44it/s]  \n",
      "100%|██████████| 5017/5017 [00:00<00:00, 11552.66it/s]\n",
      "100%|██████████| 5017/5017 [00:01<00:00, 2921.56it/s]\n",
      "100%|██████████| 5017/5017 [00:00<00:00, 347058.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5009, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_metainfo_parse(df=df,\n",
    "                    prepare_script=True,\n",
    "                    remove_other=True,\n",
    "                    remove_empty=False)\n",
    "\n",
    "df = clean_up(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['script_name_no_ext'] = df.script_name.str.split('.', expand=True)[0]\n",
    "df['main_script'] = df['script_name_no_ext']==df['Quantlet']\n",
    "df = df.loc[df['main_script']==True, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIONAL PREPROCESSING OF DESCRIPTIONS\n",
    "\n",
    "# remove parentheses\n",
    "df.Description = df.Description.str.replace(r\"\\(.+?\\)\", \"\", regex=True)\n",
    "\n",
    "# remove URL\n",
    "df.Description = df.Description.str.replace(\n",
    "r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\",\n",
    "\"\",\n",
    "regex=True)\n",
    "\n",
    "# ADDITIONAL PREPROCESSING OF CODE\n",
    "df.code_script = df.code_script.str.replace(r\"#\", \"\", regex=True)\n",
    "df.loc[df.type_script == \"m\", \"code_script\"] = df.loc[df.type_script == \"m\", \"code_script\"].str.replace(r\"\\%\", \" \", regex=True)\n",
    "\n",
    "df.loc[df.type_script == \"r\", \"code_script\"] = df.loc[df.type_script == \"r\", \"code_script\"].str.replace(r\"\\$\", \" \", regex=True)\n",
    "\n",
    "# remove the same sign repeated more than 4 times\n",
    "df.code_script = df.code_script.str.replace(r\"(.)\\1{4,}\", r\"\\1\", regex=True)\n",
    "df.code_script = df.code_script.str.replace(\"\\s{2,}\", \"\", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       Plot energy production of all relevant prosumers in testing periodAuthor: Michael KostmannLoad packages\\npackages = c(\"cowplot\",\\n\"purrr\")\\ninvisible(lapply(packages, library, character.only = TRUE))Source user-defined functions\\nfunctions = c(\" FUN get Targets. R\",\\n\" FUN generate Prices. R\",\\n\" FUN blind Auction. R\")\\ninvisible(lapply(functions, source))Function for easy string pasting\\n\"%&%\" = function(x, y) {paste(x, y, sep = \"\")}Specify paths to directories containing consumer and prosu...\n",
       "5       Save data glimpse of energy smart meter recordingsAuthor: Michael KostmannLoad packages\\npackages = c(\"data.table\",\\n\"lubridate\",\\n\"tidyverse\",\\n\"tibbletime\")\\ninvisible(lapply(packages, library, character.only = TRUE))Function for easy string pasting\\n\"%&%\" = function(x, y) {paste(x, y, sep = \"\")}Specify datasets to load\\ndataset ids = c(\"consumer/consumer-056\",\\n\"prosumer/producer-089\")Loop over datasets specified in datasets ids\\nfor(i in dataset ids) {Load raw data from csv-file\\nraw dat...\n",
       "9       Make predictions with LASSO model, and calculate error measuresfor consumer datasetsAuthor: Michael KostmannClear global environment\\nrm(list=ls())Load packages\\npackages = c(\"glmnet\",\\n\"do Parallel\")\\ninvisible(lapply(packages, library, character.only = TRUE))Source user-defined functions\\nfunctions = c(\" FUN get Data. R\",\\n\" FUN get Targets. R\",\\n\" FUN sliding LASSO Windows. R\",\\n\" FUN calc Error Measure. R\")\\ninvisible(lapply(functions, source))Specify path to directory with consumer data...\n",
       "13      Plot true and predicted consumption values in testing periodAuthor: Michael KostmannLoad user-defined functions\\npackages = c(\"cowplot\")\\ninvisible(lapply(packages, library, character.only = TRUE))\\nfunctions = c(\" FUN get Targets. R\")\\ninvisible(lapply(functions, source))Load prediction dataset\\npredictions LSTM all =\\nread.csv(\"predictions/consumer/ LSTM predictions.csv\")[, -1]\\npredictions LASSO all =\\nread.csv(\"predictions/consumer/ LASSO predictions.csv\")[, -1]\\npredictions naive all =\\...\n",
       "16      Analysis of market simulationAuthor: Michael KostmannLoad packages\\npackages = c(\"cowplot\")\\ninvisible(lapply(packages, library, character.only = TRUE))Source user-defined functions\\nfunctions = c(\" FUN get Targets. R\",\\n\" FUN settle Pred Errors. R\")\\ninvisible(lapply(functions, source))Function for easy string pasting\\n\"%&%\" = function(x, y) {paste(x, y, sep = \"\")}Specify which datasets from directories should be loaded for market analysis\\nfiles c = substring(list.files(\"../data/consumer/\"...\n",
       "                                                                                                                                                                                                                                                               ...                                                                                                                                                                                                                                                         \n",
       "5000    -Name of Quant Let: DM FsankeyPublished in: DMF - DrittmittelforschungDescription: ' Plots a sankey-plot of publications publishedin research fields.'Keywords: 'plot, sankey, connections, dependence, visualization,data visualization, analysis, discriptive methods, graphicalrepresentation, discriptive, descriptive-statistics'See also: ' DM Fchord, DM Ftsmtpe, DM Fpub Pro Pub Vol'Author: Alona ZharovaSubmitted: Sat, Jan 06 2018 by Marius Sterling, Alona ZharovaDatafile: ' DM Fsankey.csv'Input:...\n",
       "5001    -Name of Quant Let: DM FchordPublished in: Third Party Funding ( Drittmittel)Description: Plots a chord-diagram of the number of co-authorshipsby researchers aggregated w.r.t. HU- UnitsKeywords: plot, chord, adjacency matrix, visualizationSee also: DM Fsankey, DM Fvarx, DM FtsmtpeAuthor: Alona ZharovaSubmitted: Marius Sterling, Alona Zharova 20180106Datafile: DM Fchord.csvInput: a (n x n)-matrix with the number of co-authorships,additionally a matrix specifiing the colorsOutput:Example:Close...\n",
       "5002    -Name of Quant Let: DM FtstmpePublished in: DMF - DrittmittelforschungDescription: ' Plots the TPE per researcher for each university Unit(also inflation adjusted)'Keywords: 'plot, dependence, visualization, data visualization, analysis, discriptive methods, graphical representation, discriptive, descriptive-statistics'See also: ' DM Fsankey, DM Fchord, DM Fpub Pro Pub Vol'Author: Alona ZharovaSubmitted: Sat, Jan 06 2018 by Marius Sterling, Alona ZharovaDatafile: ' DM Ftsmtpe.csv'Input: '2 f...\n",
       "5003    Load required packages\\nlibrary(\" VGAM\")\\nlibrary(\"expectreg\")\\nlibrary(\"f Garch\")\\nlibrary(\"root Solve\")\\nlibrary(\"evd\")\\nlibrary(\"stabledist\")Uncomment to change your working directory setwd()Set parameters\\nRisk Level = 0.01Predetermined Value at Risk level\\nContamination = 0.2between 0 and 1, 0 = Normal, 1 = Laplace\\nwindowsize = 250Estimation window size for the rolling window\\ndistribution = \" Stable Dist\"Distribution used in TERES methodology\\nCrix = read.csv(\"crix.csv\")\\ny = Crix[, 2...\n",
       "5008    import gensim.parsing.preprocessing as gensimm\\nfrom gensim.corpora import dictionary\\nimport numpy as np\\nimport re\\nmultinom draw = np.random.multinomial\\ndef load corpus(filename, d=3):\\nimport csv, sysIncrease max line length for csv.reader:\\nmax int = sys.maxsize\\ndecrement = True\\nwhile decrement:\\ndecrement = False\\ntry:\\ncsv.field size limit(max int)\\nexcept Overflow Error:\\nmax int = int(max int/10)\\ndocs = []\\nlabelmap = dict()\\npat = re.compile(\"[ A- Z]\\d{2}\")\\nf = open(filename, ...\n",
       "Name: code_script, Length: 3367, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.code_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description_ID'] = df.groupby('Description').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from transformers import pipeline\\nclassifier = pipeline(\"zero-shot-classification\",\\n                        model=\"facebook/bart-large-mnli\")\\ncandidate_labels = [\\'project-level\\', \\'codesnippet-level\\']\\ndescriptions = df.Description.unique()\\ndescriptions[0]\\nclassifier(\"Plots the power curves by 2SQR(1), 2SQR(2) and IVX-QR in simulation.\\'\", candidate_labels)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                        model=\"facebook/bart-large-mnli\")\n",
    "candidate_labels = ['project-level', 'codesnippet-level']\n",
    "descriptions = df.Description.unique()\n",
    "descriptions[0]\n",
    "classifier(\"Plots the power curves by 2SQR(1), 2SQR(2) and IVX-QR in simulation.'\", candidate_labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# CHUNKING\\ndf[['chunk_ids', 'chunks']] = df.apply(lambda x: chunk_code(x['code_script'], chunk_size=250), axis=1, result_type='expand')\\nchunks_df = df.apply(lambda x: chunk_code(x['code_script'], chunk_size=250), axis=1, result_type='expand')\\nchunks_df.columns = ['chunk_ids', 'chunks']\\ndf[['chunk_ids', 'chunks']]  = chunks_df[['chunk_ids', 'chunks']] \\ndf = df.explode('chunk_ids').reset_index(drop=True)\\ndf['chunks'] = df.apply(lambda x: x['chunks'][x['chunk_ids']], axis=1)\\ndf.shape\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# CHUNKING\n",
    "df[['chunk_ids', 'chunks']] = df.apply(lambda x: chunk_code(x['code_script'], chunk_size=250), axis=1, result_type='expand')\n",
    "chunks_df = df.apply(lambda x: chunk_code(x['code_script'], chunk_size=250), axis=1, result_type='expand')\n",
    "chunks_df.columns = ['chunk_ids', 'chunks']\n",
    "df[['chunk_ids', 'chunks']]  = chunks_df[['chunk_ids', 'chunks']] \n",
    "df = df.explode('chunk_ids').reset_index(drop=True)\n",
    "df['chunks'] = df.apply(lambda x: x['chunks'][x['chunk_ids']], axis=1)\n",
    "df.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CmQLCYodJUqs"
   },
   "outputs": [],
   "source": [
    "df[\"Q_ID\"] = df.index\n",
    "\n",
    "folder_to_save = f\"../../data/preprocessed/Quantlet/{DATE}/\"\n",
    "if not os.path.exists(folder_to_save):\n",
    "    os.mkdir(folder_to_save)\n",
    "\n",
    "df.to_csv(f'{folder_to_save}full_{DATE}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"code_list = df.groupby(['folder_name'])['type_script'].apply(list)\\ndf['type_script'] = df['folder_name'].map(code_list)\\ndf['type_script'] = df['type_script'].apply(lambda x: ' '.join(x))\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{folder_to_save}full_{DATE}.csv')\n",
    "\n",
    "'''code_list = df.groupby(['folder_name'])['code_script'].apply(list)\n",
    "df['code_script'] = df['folder_name'].map(code_list)\n",
    "df['code_script'] = df['code_script'].apply(lambda x: '\\n\\n'.join(x))'''\n",
    "\n",
    "'''code_list = df.groupby(['folder_name'])['type_script'].apply(list)\n",
    "df['type_script'] = df['folder_name'].map(code_list)\n",
    "df['type_script'] = df['type_script'].apply(lambda x: ' '.join(x))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print(df[['code_script', 'Quantlet', 'Description', 'Description_ID', 'Q_ID', 'folder_name', 'repo', 'Authors']].shape)\\n\\ndf_reduced = df[['code_script', 'Quantlet', 'Description', 'Description_ID', 'type_script', 'folder_name', 'repo', 'Authors']].drop_duplicates(['Quantlet', 'Description', 'Description_ID', 'folder_name', 'repo', 'Authors'])\\ndf_reduced.shape\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(df[['code_script', 'Quantlet', 'Description', 'Description_ID', 'Q_ID', 'folder_name', 'repo', 'Authors']].shape)\n",
    "\n",
    "df_reduced = df[['code_script', 'Quantlet', 'Description', 'Description_ID', 'type_script', 'folder_name', 'repo', 'Authors']].drop_duplicates(['Quantlet', 'Description', 'Description_ID', 'folder_name', 'repo', 'Authors'])\n",
    "df_reduced.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT THE DATA GROUP QUANTLET\n",
    "labelled_descr_id, test_descr_id = train_test_split(list(df.Description_ID.unique()),\n",
    "                test_size=0.1,\n",
    "                random_state=RS)\n",
    "train_descr_id, val_descr_id = train_test_split(labelled_descr_id,\n",
    "                test_size=0.1,\n",
    "                random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wTr5ZFiOKEND"
   },
   "outputs": [],
   "source": [
    "full_train = df.loc[df.Description_ID.isin(labelled_descr_id)]\n",
    "train = df.loc[df.Description_ID.isin(train_descr_id)]\n",
    "val = df.loc[df.Description_ID.isin(val_descr_id)]\n",
    "test = df.loc[df.Description_ID.isin(test_descr_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2735, 17)\n",
      "r     0.562706\n",
      "m     0.231444\n",
      "py    0.205850\n",
      "Name: type_script, dtype: float64\n",
      "(305, 17)\n",
      "r     0.544262\n",
      "py    0.229508\n",
      "m     0.226230\n",
      "Name: type_script, dtype: float64\n",
      "(327, 17)\n",
      "r     0.584098\n",
      "m     0.247706\n",
      "py    0.168196\n",
      "Name: type_script, dtype: float64\n",
      "(2735, 17)\n",
      "r     1539\n",
      "m      633\n",
      "py     563\n",
      "Name: type_script, dtype: int64\n",
      "(305, 17)\n",
      "r     166\n",
      "py     70\n",
      "m      69\n",
      "Name: type_script, dtype: int64\n",
      "(327, 17)\n",
      "r     191\n",
      "m      81\n",
      "py     55\n",
      "Name: type_script, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/usr/net/zinovyee.hub/IRTG/MLSC/Encode-the-Qode/Quantlet/3-data-preprocessing/preprocessing_utils.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Authors\"] = train[\"Authors\"].fillna(\"Unknown\")\n",
      "/usr/net/zinovyee.hub/IRTG/MLSC/Encode-the-Qode/Quantlet/3-data-preprocessing/preprocessing_utils.py:407: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val[\"Authors\"] = val[\"Authors\"].fillna(\"Unknown\")\n",
      "/usr/net/zinovyee.hub/IRTG/MLSC/Encode-the-Qode/Quantlet/3-data-preprocessing/preprocessing_utils.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"Authors\"] = test[\"Authors\"].fillna(\"Unknown\")\n",
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "save_datasets(full_train, train, val, test, DATE, RS, 'code_script', False, True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN1WASBG9SoZypHtCRaCZX/",
   "mount_file_id": "19c37YEU8LH5C0d1bxiNpE23xesKn01ad",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
