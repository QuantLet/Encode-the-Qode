{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd7S7ZIIS6Fn"
   },
   "source": [
    "################################################################################\n",
    "# 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QjyD6T4D1XM4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g4K0YWK11RjR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "QPATH = \"Quantlet/3-data-preprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xz1ksIsd1SYO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREPARE WORKING DIRECTORY\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.chdir(\n",
    "        f\"/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}\"\n",
    "    )\n",
    "else:\n",
    "    os.chdir(\"./\")\n",
    "\n",
    "# sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TNkVUfU21UsR",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/RDC/zinovyee.hub/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# PACKAGES\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import importlib\n",
    "import preprocessing_utils\n",
    "\n",
    "importlib.reload(preprocessing_utils)\n",
    "from preprocessing_utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Levenshtein import distance\n",
    "\n",
    "# SETTINGS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Fkzpboq6sy"
   },
   "source": [
    "# 2. Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATE = \"20231014\"\n",
    "RS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/Quantlets_{DATE}.pkl\", \"rb\"\n",
    ") as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4837, 6)\n",
      "(4837, 12)\n"
     ]
    }
   ],
   "source": [
    "df_long = df_metainfo_parse(df=df, prepare_script=True, remove_other=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HSsWU3MmGSj9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STF-ToDo                           368\n",
       "SFE                                290\n",
       "MVA-ToDo                           249\n",
       "MVA                                225\n",
       "STF                                224\n",
       "                                  ... \n",
       "loadcrix                             1\n",
       "21-SFM1-TS-Project-Xingjia-Wang      1\n",
       "CoinGeckoCrawler                     1\n",
       "Anomaly-Detection                    1\n",
       "Disaster                             1\n",
       "Name: repo, Length: 328, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.repo.value_counts()\n",
    "\n",
    "# 4 groups\n",
    "\n",
    "# no neighbors\n",
    "# less than 5 neighbors\n",
    "# between 5 and 10 neighbors\n",
    "# more than 10 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 4837/4837 [00:00<00:00, 662720.04it/s]\n",
      "100%|███████████████████████████████████████| 4837/4837 [01:11<00:00, 67.88it/s]\n",
      "100%|███████████████████████████████████| 4837/4837 [00:00<00:00, 921379.19it/s]\n",
      "100%|████████████████████████████████████| 4837/4837 [00:00<00:00, 11201.55it/s]\n",
      "100%|███████████████████████████████████| 4837/4837 [00:00<00:00, 937776.11it/s]\n",
      "100%|█████████████████████████████████████| 4837/4837 [00:01<00:00, 3700.03it/s]\n",
      "100%|███████████████████████████████████| 4837/4837 [00:00<00:00, 914237.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4829, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_long = clean_up(df_long)\n",
    "print(df_long.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CmQLCYodJUqs"
   },
   "outputs": [],
   "source": [
    "df_long[\"Q_ID\"] = df_long.index\n",
    "\n",
    "df_long.to_csv(f\"../../data/preprocessed/Quantlet/{DATE}/full_{DATE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WtBMV1VFAVHf"
   },
   "outputs": [],
   "source": [
    "# CLEAN DESCRIPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-ClyiPTu_tjr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 4829/4829 [00:00<00:00, 42427.23it/s]\n"
     ]
    }
   ],
   "source": [
    "df_long[\"url\"] = df_long.progress_apply(combine_url, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ITt9WLZNA-Bw"
   },
   "outputs": [],
   "source": [
    "df_long[[\"Description\", \"url\"]].to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/Description_annotation_{DATE}.csv\",\n",
    "    index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wTr5ZFiOKEND"
   },
   "outputs": [],
   "source": [
    "# SPLIT THE DATA\n",
    "labelled_qs, test_qs = train_test_split(\n",
    "    list(df_long.Quantlet.unique()), test_size=0.1, random_state=RS\n",
    ")\n",
    "train_qs, val_qs = train_test_split(labelled_qs, test_size=0.1, random_state=RS)\n",
    "\n",
    "\n",
    "train = df_long[df_long[\"Quantlet\"].isin(set(train_qs))].reset_index(drop=True)\n",
    "val = df_long[df_long[\"Quantlet\"].isin(set(val_qs))].reset_index(drop=True)\n",
    "test = df_long[df_long[\"Quantlet\"].isin(set(test_qs))].reset_index(drop=True)\n",
    "\n",
    "full_train = (\n",
    "    pd.concat([train, val], axis=0)\n",
    "    .sample(frac=1, random_state=RS)\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UIINKvxN_0P3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3968, 17)\n",
      "r     0.453881\n",
      "m     0.287802\n",
      "py    0.258317\n",
      "Name: type_script, dtype: float64\n",
      "(399, 17)\n",
      "r     0.513784\n",
      "m     0.255639\n",
      "py    0.230576\n",
      "Name: type_script, dtype: float64\n",
      "(462, 17)\n",
      "r     0.504329\n",
      "m     0.287879\n",
      "py    0.207792\n",
      "Name: type_script, dtype: float64\n",
      "(3968, 17)\n",
      "r     1801\n",
      "m     1142\n",
      "py    1025\n",
      "Name: type_script, dtype: int64\n",
      "(399, 17)\n",
      "r     205\n",
      "m     102\n",
      "py     92\n",
      "Name: type_script, dtype: int64\n",
      "(462, 17)\n",
      "r     233\n",
      "m     133\n",
      "py     96\n",
      "Name: type_script, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "full_train.to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/full_train_df_{DATE}_sample0.csv\",\n",
    "    index=False,\n",
    ")\n",
    "train.to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/train_df_{DATE}_sample0.csv\", index=False\n",
    ")\n",
    "val.to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/val_df_{DATE}_sample0.csv\", index=False\n",
    ")\n",
    "test.to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/test_df_{DATE}_sample0.csv\", index=False\n",
    ")\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(train[\"type_script\"].value_counts(normalize=True))\n",
    "print(val.shape)\n",
    "print(val[\"type_script\"].value_counts(normalize=True))\n",
    "print(test.shape)\n",
    "print(test[\"type_script\"].value_counts(normalize=True))\n",
    "\n",
    "print(train.shape)\n",
    "print(train[\"type_script\"].value_counts(normalize=False))\n",
    "print(val.shape)\n",
    "print(val[\"type_script\"].value_counts(normalize=False))\n",
    "print(test.shape)\n",
    "print(test[\"type_script\"].value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.loc[\n",
    "    test[\"Description\"].isna(), \"Description\"\n",
    "] = \"Find out the potential anomalies of variable –Tran Count, and visualize the results.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Q1FyNqapMVUl"
   },
   "outputs": [],
   "source": [
    "for MODE in [\"no_context\", \"author\", \"repo\"]:\n",
    "    full_train = pd.read_csv(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/full_train_df_{DATE}_sample0.csv\"\n",
    "    )\n",
    "    train = pd.read_csv(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/train_df_{DATE}_sample0.csv\"\n",
    "    )\n",
    "    val = pd.read_csv(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/val_df_{DATE}_sample0.csv\"\n",
    "    )\n",
    "    test = pd.read_csv(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/test_df_{DATE}_sample0.csv\"\n",
    "    )\n",
    "\n",
    "    # FIX NA\n",
    "    test.loc[test[\"Quantlet\"].isna(), \"Quantlet\"] = \"XFGexp_rtn_SRM_2d_DOENST RUN\"\n",
    "    train[\"Authors\"] = train[\"Authors\"].fillna(\"Unknown\")\n",
    "    val[\"Authors\"] = val[\"Authors\"].fillna(\"Unknown\")\n",
    "    test[\"Authors\"] = test[\"Authors\"].fillna(\"Unknown\")\n",
    "\n",
    "    if MODE == \"repo\":\n",
    "        train.loc[:, \"code_script\"] = (\n",
    "            \"# repo: \" + train[\"repo\"] + \"\\n \" + train[\"code_script\"]\n",
    "        )\n",
    "        val.loc[:, \"code_script\"] = (\n",
    "            \"# repo: \" + val[\"repo\"] + \"\\n \" + val[\"code_script\"]\n",
    "        )\n",
    "        test.loc[:, \"code_script\"] = (\n",
    "            \"# repo: \" + test[\"repo\"] + \"\\n \" + test[\"code_script\"]\n",
    "        )\n",
    "\n",
    "    elif MODE == \"author\":\n",
    "        train.loc[:, \"code_script\"] = (\n",
    "            \"# author: \" + train[\"Authors\"] + \"\\n \" + train[\"code_script\"]\n",
    "        )\n",
    "        val.loc[:, \"code_script\"] = (\n",
    "            \"# author: \" + val[\"Authors\"] + \"\\n \" + val[\"code_script\"]\n",
    "        )\n",
    "        test.loc[:, \"code_script\"] = (\n",
    "            \"# author: \" + test[\"Authors\"] + \"\\n \" + test[\"code_script\"]\n",
    "        )\n",
    "\n",
    "    train_dataset_json = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"input_sequence\": train[\"code_script\"].iloc[i],\n",
    "                \"output_sequence\": train[\"Description\"].iloc[i],\n",
    "            }\n",
    "            for i in range(train.shape[0])\n",
    "        ],\n",
    "    }\n",
    "    val_dataset_json = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"input_sequence\": val[\"code_script\"].iloc[i],\n",
    "                \"output_sequence\": val[\"Description\"].iloc[i],\n",
    "            }\n",
    "            for i in range(val.shape[0])\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    full_train_dataset_json = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"input_sequence\": full_train[\"code_script\"].iloc[i],\n",
    "                \"output_sequence\": full_train[\"Description\"].iloc[i],\n",
    "            }\n",
    "            for i in range(full_train.shape[0])\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    test_dataset_json = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"input_sequence\": test[\"code_script\"].iloc[i],\n",
    "                \"output_sequence\": test[\"Description\"].iloc[i],\n",
    "            }\n",
    "            for i in range(test.shape[0])\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with open(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/{MODE}/full_train_dataset_{DATE}_sample0.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(full_train_dataset_json, f)\n",
    "\n",
    "    with open(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/{MODE}/train_dataset_{DATE}_sample0.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(train_dataset_json, f)\n",
    "\n",
    "    with open(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/{MODE}/val_dataset_{DATE}_sample0.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(val_dataset_json, f)\n",
    "\n",
    "    with open(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/{MODE}/test_dataset_{DATE}_sample0.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(test_dataset_json, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN1WASBG9SoZypHtCRaCZX/",
   "mount_file_id": "19c37YEU8LH5C0d1bxiNpE23xesKn01ad",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "encode_code",
   "language": "python",
   "name": "encode_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
