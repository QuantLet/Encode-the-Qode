{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd7S7ZIIS6Fn"
   },
   "source": [
    "################################################################################\n",
    "# 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "QjyD6T4D1XM4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "g4K0YWK11RjR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "QPATH = \"Quantlet/3-data-preprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Xz1ksIsd1SYO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREPARE WORKING DIRECTORY\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.chdir(\n",
    "        f\"/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}\"\n",
    "    )\n",
    "else:\n",
    "    os.chdir(\"./\")\n",
    "\n",
    "# sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "TNkVUfU21UsR",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/RDC/zinovyee.hub/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# PACKAGES\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import importlib\n",
    "import preprocessing_utils\n",
    "\n",
    "importlib.reload(preprocessing_utils)\n",
    "from preprocessing_utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Levenshtein import distance\n",
    "\n",
    "# SETTINGS\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Fkzpboq6sy"
   },
   "source": [
    "# 2. Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATE = \"20231014\"\n",
    "RS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/Quantlets_{DATE}.pkl\", \"rb\"\n",
    ") as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4837, 6)\n",
      "(4836, 12)\n"
     ]
    }
   ],
   "source": [
    "df_long = df_metainfo_parse(df=df, prepare_script=True, remove_other=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "HSsWU3MmGSj9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STF-ToDo                 368\n",
       "SFE                      290\n",
       "MVA-ToDo                 249\n",
       "MVA                      225\n",
       "STF                      224\n",
       "                        ... \n",
       "SVCJ_MC                    1\n",
       "DAIIkmeansEM               1\n",
       "CardSpentplot              1\n",
       "network_BTC_exchanges      1\n",
       "Disaster                   1\n",
       "Name: repo, Length: 327, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.repo.value_counts()\n",
    "\n",
    "# 4 groups\n",
    "\n",
    "# no neighbors\n",
    "# less than 5 neighbors\n",
    "# between 5 and 10 neighbors\n",
    "# more than 10 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 4836/4836 [00:00<00:00, 596122.20it/s]\n",
      "100%|███████████████████████████████████████| 4836/4836 [01:12<00:00, 66.47it/s]\n",
      "100%|███████████████████████████████████| 4836/4836 [00:00<00:00, 901736.20it/s]\n",
      "100%|█████████████████████████████████████| 4836/4836 [00:00<00:00, 9295.47it/s]\n",
      "100%|███████████████████████████████████| 4836/4836 [00:00<00:00, 715700.02it/s]\n",
      "100%|█████████████████████████████████████| 4836/4836 [00:01<00:00, 3349.81it/s]\n",
      "100%|███████████████████████████████████| 4836/4836 [00:00<00:00, 918477.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4828, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_long = clean_up(df_long)\n",
    "print(df_long.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "CmQLCYodJUqs"
   },
   "outputs": [],
   "source": [
    "df_long[\"Q_ID\"] = df_long.index\n",
    "\n",
    "df_long.to_csv(f\"../../data/preprocessed/Quantlet/{DATE}/full_{DATE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "WtBMV1VFAVHf"
   },
   "outputs": [],
   "source": [
    "# CLEAN DESCRIPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "-ClyiPTu_tjr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 4828/4828 [00:00<00:00, 40154.71it/s]\n"
     ]
    }
   ],
   "source": [
    "df_long[\"url\"] = df_long.progress_apply(combine_url, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ITt9WLZNA-Bw"
   },
   "outputs": [],
   "source": [
    "df_long[[\"Description\", \"url\"]].to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/Description_annotation_{DATE}.csv\",\n",
    "    index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_name</th>\n",
       "      <th>code_script</th>\n",
       "      <th>type_script</th>\n",
       "      <th>script_name</th>\n",
       "      <th>Quantlet</th>\n",
       "      <th>Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Authors</th>\n",
       "      <th>scr_n</th>\n",
       "      <th>description_len</th>\n",
       "      <th>description_n_words</th>\n",
       "      <th>repo</th>\n",
       "      <th>code_len</th>\n",
       "      <th>new_len</th>\n",
       "      <th>new_len2</th>\n",
       "      <th>Q_ID</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [folder_name, code_script, type_script, script_name, Quantlet, Description, Keywords, Authors, scr_n, description_len, description_n_words, repo, code_len, new_len, new_len2, Q_ID, url]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long[df_long.Description == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "wTr5ZFiOKEND"
   },
   "outputs": [],
   "source": [
    "# SPLIT THE DATA\n",
    "labelled_qs, test_qs = train_test_split(\n",
    "    list(df_long.Quantlet.unique()), test_size=0.1, random_state=RS\n",
    ")\n",
    "train_qs, val_qs = train_test_split(labelled_qs, test_size=0.1, random_state=RS)\n",
    "\n",
    "\n",
    "train = df_long[df_long[\"Quantlet\"].isin(set(train_qs))].reset_index(drop=True)\n",
    "val = df_long[df_long[\"Quantlet\"].isin(set(val_qs))].reset_index(drop=True)\n",
    "test = df_long[df_long[\"Quantlet\"].isin(set(test_qs))].reset_index(drop=True)\n",
    "\n",
    "full_train = (\n",
    "    pd.concat([train, val], axis=0)\n",
    "    .sample(frac=1, random_state=RS)\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "UIINKvxN_0P3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3966, 17)\n",
      "r     0.458396\n",
      "m     0.289460\n",
      "py    0.252143\n",
      "Name: type_script, dtype: float64\n",
      "(432, 17)\n",
      "r     0.472222\n",
      "py    0.275463\n",
      "m     0.252315\n",
      "Name: type_script, dtype: float64\n",
      "(430, 17)\n",
      "r     0.504651\n",
      "m     0.279070\n",
      "py    0.216279\n",
      "Name: type_script, dtype: float64\n",
      "(3966, 17)\n",
      "r     1818\n",
      "m     1148\n",
      "py    1000\n",
      "Name: type_script, dtype: int64\n",
      "(432, 17)\n",
      "r     204\n",
      "py    119\n",
      "m     109\n",
      "Name: type_script, dtype: int64\n",
      "(430, 17)\n",
      "r     217\n",
      "m     120\n",
      "py     93\n",
      "Name: type_script, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "full_train.to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/full_train_df_{DATE}_sample0.csv\",\n",
    "    index=False,\n",
    ")\n",
    "train.to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/train_df_{DATE}_sample0.csv\", index=False\n",
    ")\n",
    "val.to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/val_df_{DATE}_sample0.csv\", index=False\n",
    ")\n",
    "test.to_csv(\n",
    "    f\"../../data/preprocessed/Quantlet/{DATE}/test_df_{DATE}_sample0.csv\", index=False\n",
    ")\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(train[\"type_script\"].value_counts(normalize=True))\n",
    "print(val.shape)\n",
    "print(val[\"type_script\"].value_counts(normalize=True))\n",
    "print(test.shape)\n",
    "print(test[\"type_script\"].value_counts(normalize=True))\n",
    "\n",
    "print(train.shape)\n",
    "print(train[\"type_script\"].value_counts(normalize=False))\n",
    "print(val.shape)\n",
    "print(val[\"type_script\"].value_counts(normalize=False))\n",
    "print(test.shape)\n",
    "print(test[\"type_script\"].value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Q1FyNqapMVUl"
   },
   "outputs": [],
   "source": [
    "for MODE in [\"no_context\", \"author\", \"repo\"]:\n",
    "    full_train = pd.read_csv(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/full_train_df_{DATE}_sample0.csv\"\n",
    "    )\n",
    "    train = pd.read_csv(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/train_df_{DATE}_sample0.csv\"\n",
    "    )\n",
    "    val = pd.read_csv(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/val_df_{DATE}_sample0.csv\"\n",
    "    )\n",
    "    test = pd.read_csv(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/test_df_{DATE}_sample0.csv\"\n",
    "    )\n",
    "\n",
    "    # FIX NA\n",
    "    test.loc[test[\"Quantlet\"].isna(), \"Quantlet\"] = \"XFGexp_rtn_SRM_2d_DOENST RUN\"\n",
    "    train[\"Authors\"] = train[\"Authors\"].fillna(\"Unknown\")\n",
    "    val[\"Authors\"] = val[\"Authors\"].fillna(\"Unknown\")\n",
    "    test[\"Authors\"] = test[\"Authors\"].fillna(\"Unknown\")\n",
    "\n",
    "    if MODE == \"repo\":\n",
    "        train.loc[:, \"code_script\"] = (\n",
    "            \"# repo: \" + train[\"repo\"] + \"\\n \" + train[\"code_script\"]\n",
    "        )\n",
    "        val.loc[:, \"code_script\"] = (\n",
    "            \"# repo: \" + val[\"repo\"] + \"\\n \" + val[\"code_script\"]\n",
    "        )\n",
    "        test.loc[:, \"code_script\"] = (\n",
    "            \"# repo: \" + test[\"repo\"] + \"\\n \" + test[\"code_script\"]\n",
    "        )\n",
    "\n",
    "    elif MODE == \"author\":\n",
    "        train.loc[:, \"code_script\"] = (\n",
    "            \"# author: \" + train[\"Authors\"] + \"\\n \" + train[\"code_script\"]\n",
    "        )\n",
    "        val.loc[:, \"code_script\"] = (\n",
    "            \"# author: \" + val[\"Authors\"] + \"\\n \" + val[\"code_script\"]\n",
    "        )\n",
    "        test.loc[:, \"code_script\"] = (\n",
    "            \"# author: \" + test[\"Authors\"] + \"\\n \" + test[\"code_script\"]\n",
    "        )\n",
    "\n",
    "    train_dataset_json = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"input_sequence\": train[\"code_script\"].iloc[i],\n",
    "                \"output_sequence\": train[\"Description\"].iloc[i],\n",
    "            }\n",
    "            for i in range(train.shape[0])\n",
    "        ],\n",
    "    }\n",
    "    val_dataset_json = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"input_sequence\": val[\"code_script\"].iloc[i],\n",
    "                \"output_sequence\": val[\"Description\"].iloc[i],\n",
    "            }\n",
    "            for i in range(val.shape[0])\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    full_train_dataset_json = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"input_sequence\": full_train[\"code_script\"].iloc[i],\n",
    "                \"output_sequence\": full_train[\"Description\"].iloc[i],\n",
    "            }\n",
    "            for i in range(full_train.shape[0])\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    test_dataset_json = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"input_sequence\": test[\"code_script\"].iloc[i],\n",
    "                \"output_sequence\": test[\"Description\"].iloc[i],\n",
    "            }\n",
    "            for i in range(test.shape[0])\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with open(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/{MODE}/full_train_dataset_{DATE}_sample0.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(full_train_dataset_json, f)\n",
    "\n",
    "    with open(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/{MODE}/train_dataset_{DATE}_sample0.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(train_dataset_json, f)\n",
    "\n",
    "    with open(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/{MODE}/val_dataset_{DATE}_sample0.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(val_dataset_json, f)\n",
    "\n",
    "    with open(\n",
    "        f\"../../data/preprocessed/Quantlet/{DATE}/{MODE}/test_dataset_{DATE}_sample0.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(test_dataset_json, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN1WASBG9SoZypHtCRaCZX/",
   "mount_file_id": "19c37YEU8LH5C0d1bxiNpE23xesKn01ad",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "encode_code",
   "language": "python",
   "name": "encode_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
