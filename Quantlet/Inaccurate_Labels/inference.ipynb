{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JZal6ahJZQBU"},"outputs":[],"source":["#%pip install protobuf==3.20.1\n","%pip install transformers[torch]\n","%pip install -q sentencepiece\n","%pip install datasets==2.13.1\n","%pip install evaluate\n","%pip install rouge_score\n","#%pip install git+https://github.com/huggingface/nlp.git@fix-bad-type-in-overflow-check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5Mlzgdzaliu"},"outputs":[],"source":["QPATH = \"Quantlet/4-qode2desc\""]},{"cell_type":"code","execution_count":2,"metadata":{"id":"iaAT_m3NaEzp"},"outputs":[],"source":["import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","import os\n","#if IN_COLAB:\n","#  os.chdir(f'/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"oRmp1O7SZgaI"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /home/RDC/zinovyee.hub/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import pickle\n","import json\n","import re\n","import sys\n","from IPython.display import display\n","import datetime\n","\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","tqdm.pandas()\n","\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","from torch.utils.data import  DataLoader\n","from transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline\n","from transformers import AdamW\n","from datasets import load_dataset\n","\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","\n","import nltk\n","nltk.download('punkt')\n","import evaluate\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CbZX3Y3_q1pw"},"outputs":[],"source":["encoder_max_length = 512\n","decoder_max_length = 150\n","RS = 42\n","LR = 5e-5\n","\n","EPOCHS = 10\n","TRAIN_BATCH = 16\n","EVAL_BATCH  = 4\n","\n","WARMUP_STEPS  = 500\n","WEIGHT_DECAY  = 0.1\n","LOGGING_STEPS = 100\n","SAVE_TOTAL_LIM = 1\n","SAVE_STRATEGY = 'steps'\n","\n","LABEL_SMOOTHING  = 0.1\n","PREDICT_GENERATE = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uumjWAR9W4Dh"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WuZlxcpZW76m"},"outputs":[],"source":["model = AutoModelWithLMHead.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)\n","model.to(device)\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEENu_5TXWdH"},"outputs":[],"source":["#train.to_csv('../../data/preprocessed/Quantlet/train_df_with_domain_200231002.csv', index=False)\n","#val.to_csv('../../data/preprocessed/Quantlet/val_df_with_domain_200231002.csv', index=False)\n","test = pd.read_csv('../../data/preprocessed/Quantlet/test_df_with_domain_20231002.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"goEvZfRyXehx"},"outputs":[],"source":["test_dataset_json = {'version' : '10.1',\n","                    'data' : [{'input_sequence'  : test['code_script'].iloc[i],\n","                              'output_sequence' : test['Description'].iloc[i]} for i in range(test.shape[0])]}\n","\n","with open('test.json', 'w') as f:\n","  json.dump(test_dataset_json, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZT2x0J4BW-ss"},"outputs":[],"source":["test_dataset = load_dataset(\"json\",\n","                            data_files='test.json',\n","                            field=\"data\",\n","                            data_dir='./')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrXku646YVDH"},"outputs":[],"source":["validation_data_txt = test_dataset['train']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"URKuhVuiYXaj"},"outputs":[],"source":["validation_data = validation_data_txt.map(\n","        lambda batch: analysis_modules.batch_tokenize_preprocess(\n","            batch,\n","            tokenizer=tokenizer,\n","            max_input_length=encoder_max_length,\n","            max_output_length=decoder_max_length\n","        ),\n","        batched=True,\n","        remove_columns=validation_data_txt.column_names,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HhgUwXyYraf"},"outputs":[],"source":["def generate_summary(test_samples, model, tokenizer, encoder_max_length):\n","    inputs = tokenizer(\n","        test_samples[\"input_sequence\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=encoder_max_length,\n","        return_tensors=\"pt\",\n","    )\n","    input_ids = inputs.input_ids.to(model.device)\n","    attention_mask = inputs.attention_mask.to(model.device)\n","    outputs = model.generate(input_ids, attention_mask=attention_mask)\n","    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    return outputs, output_str"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmHALH4OYmvJ"},"outputs":[],"source":["summaries_before_tuning = generate_summary(validation_data_txt,\n","                                            model,\n","                                            tokenizer,\n","                                            encoder_max_length)[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pBcckEhWt9i"},"outputs":[],"source":["\n","\n","    validation_data_txt = test_dataset['train']\n","\n","    train_data = train_data_txt.map(\n","        lambda batch: batch_tokenize_preprocess(\n","            batch,\n","            tokenizer=tokenizer,\n","            max_input_length=encoder_max_length,\n","            max_output_length=decoder_max_length\n","        ),\n","        batch_size=8,\n","        batched=True,\n","        remove_columns=train_data_txt.column_names,\n","    )\n","\n","    validation_data = validation_data_txt.map(\n","        lambda batch: batch_tokenize_preprocess(\n","            batch,\n","            tokenizer=tokenizer,\n","            max_input_length=encoder_max_length,\n","            max_output_length=decoder_max_length\n","        ),\n","        batched=True,\n","        remove_columns=validation_data_txt.column_names,\n","    )\n","\n","\n","    # SUBSAMPLE FOR GENERATION BEFORE TUNING\n","    test_samples = validation_data_txt.select(range(20))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRHaw5S7X81D"},"outputs":[],"source":["import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9t6d_nrX_lyy"},"outputs":[],"source":["print(analysis_name)\n","analysis_modules.scs_analyze(analysis_name=analysis_name,\n","                                    model_name=model_name,\n","                                    train_data_path=f'../../data/preprocessed/Quantlet/{MODE}/',\n","                                    train_data_name='full_train_dataset_20230923.json',\n","                                    val_data_path=f'../../data/preprocessed/Quantlet/{MODE}/',\n","                                    val_data_name='test_dataset_20230923.json',\n","                                    encoder_max_length=encoder_max_length,\n","                                    decoder_max_length=decoder_max_length,\n","                                    random_state=RS,\n","                                    eval_columns_list=EVAL_COLUMNS,\n","                                    learning_rate=LR,\n","                                    epochs=EPOCHS,\n","                                    train_batch=TRAIN_BATCH,\n","                                    eval_batch=EVAL_BATCH,\n","                                    warmup_steps=WARMUP_STEPS,\n","                                    weight_decay=WEIGHT_DECAY,\n","                                    logging_stes=LOGGING_STEPS,\n","                                    save_total_lim=SAVE_TOTAL_LIM,\n","                                    save_strategy=SAVE_STRATEGY,\n","                                    label_smooting=LABEL_SMOOTHING,\n","                                    predict_generate=PREDICT_GENERATE,\n","                                    load_best_model_at_end=load_best_model_at_end)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZoeldwQcIkFZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMNJ1jmmQHTDVYUIoFd4kfE","gpuType":"A100","machine_shape":"hm","mount_file_id":"1IqoM1FUCqaM6g5E5MHKk7zlgkl6pUwHA","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
