{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JZal6ahJZQBU"},"outputs":[],"source":["%%capture\n","#%pip install protobuf==3.20.1\n","%pip install transformers[torch]\n","%pip install -q sentencepiece\n","%pip install datasets==2.13.1\n","%pip install evaluate\n","%pip install rouge_score\n","#%pip install git+https://github.com/huggingface/nlp.git@fix-bad-type-in-overflow-check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5Mlzgdzaliu"},"outputs":[],"source":["QPATH = \"Quantlet/4-qode2desc\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaAT_m3NaEzp"},"outputs":[],"source":["import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","import os\n","if IN_COLAB:\n","  os.chdir(f'/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oRmp1O7SZgaI"},"outputs":[],"source":["import pickle\n","import json\n","import re\n","import sys\n","from IPython.display import display\n","import datetime\n","\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","tqdm.pandas()\n","\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","from torch.utils.data import  DataLoader\n","from transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline\n","from transformers import AdamW\n","from datasets import load_dataset\n","\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","\n","import nltk\n","nltk.download('punkt')\n","import evaluate\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["import importlib\n","import analysis_modules\n","importlib.reload(analysis_modules)"],"metadata":{"id":"kM604UgeBuMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CbZX3Y3_q1pw"},"outputs":[],"source":["model_name = '../5-domain-pre-training/results/checkpoint-12290'"]},{"cell_type":"code","source":["import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"FRHaw5S7X81D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelWithLMHead.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)"],"metadata":{"id":"9t6d_nrX_lyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_summary(test_samples, model, tokenizer, encoder_max_length):\n","    inputs = tokenizer(\n","        test_samples[\"input_sequence\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=encoder_max_length,\n","        return_tensors=\"pt\",\n","    )\n","    input_ids = inputs.input_ids.to(model.device)\n","    attention_mask = inputs.attention_mask.to(model.device)\n","    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length =150)\n","    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    return outputs, output_str"],"metadata":{"id":"ZoeldwQcIkFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def batch_tokenize_preprocess(batch,\n","                              tokenizer,\n","                              max_input_length,\n","                              max_output_length):\n","\n","    source = batch[\"input_sequence\"]\n","    target = batch[\"output_sequence\"]\n","\n","    source_tokenized = tokenizer(\n","        source,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_input_length\n","    )\n","\n","    target_tokenized = tokenizer(\n","        target,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_output_length\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","\n","    # Ignore padding in the loss\n","\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","\n","    return batch"],"metadata":{"id":"sC67g4yM6hV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_max_length = 512\n","decoder_max_length = 300"],"metadata":{"id":"bGzD5nZ96ql_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = load_dataset(\"json\",\n","                            data_files='test_dataset_20231007.json',\n","                            field=\"data\",\n","                            data_dir='../../data/preprocessed/Quantlet/no_context/')\n","\n","\n","validation_data_txt = test_dataset['train']\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch,\n","        tokenizer=tokenizer,\n","        max_input_length=encoder_max_length,\n","        max_output_length=decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")\n"],"metadata":{"id":"hP5f8PEc5qJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SUBSAMPLE FOR GENERATION BEFORE TUNING\n","test_samples = validation_data_txt.select(range(20))\n","summaries_before_tuning = generate_summary(test_samples,\n","                                            model,\n","                                            tokenizer,\n","                                            encoder_max_length)[1]"],"metadata":{"id":"XX0g8axk6huo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rouge = evaluate.load('rouge')\n","bleu = evaluate.load('bleu')\n","\n","references = test_samples['output_sequence']\n","predictions = summaries_before_tuning\n","results = rouge.compute(predictions=predictions, references=references)\n","\n","bleu = bleu.compute(predictions=predictions, references=references)"],"metadata":{"id":"BhQORzUP8Fd_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["validation_data_txt['output_sequence']"],"metadata":{"id":"xLRXM35V9DmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions"],"metadata":{"id":"-fsbDqTl8pqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bleu"],"metadata":{"id":"-xnh_Lhg8kZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results"],"metadata":{"id":"EalmOChG8VCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_samples['output_sequence']"],"metadata":{"id":"mBxRN9-U7Ild"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summaries_before_tuning"],"metadata":{"id":"omaB3dDt607c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EXXmByV261EO"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","private_outputs":true,"provenance":[],"gpuType":"A100","mount_file_id":"1KmVoyMPZSwzHSRWIrLeTrINehi2VHCt1","authorship_tag":"ABX9TyM4Hr9k83UY5HSTUyHOKG4Q"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}