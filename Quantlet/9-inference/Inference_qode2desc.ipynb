{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"O5Mlzgdzaliu"},"outputs":[],"source":["QPATH = \"Quantlet/4-qode2desc\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"iaAT_m3NaEzp"},"outputs":[],"source":["import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","import os\n","if IN_COLAB:\n","  os.chdir(f'/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oRmp1O7SZgaI"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /home/RDC/zinovyee.hub/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import pickle\n","import json\n","import re\n","import sys\n","from IPython.display import display\n","import datetime\n","\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","tqdm.pandas()\n","\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","from torch.utils.data import  DataLoader\n","from transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline\n","from transformers import AdamW\n","from datasets import load_dataset\n","\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","\n","import nltk\n","nltk.download('punkt')\n","import evaluate\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"CbZX3Y3_q1pw"},"outputs":[],"source":["model_name = \"/home/RDC/zinovyee.hub/H:/zinovyee.hub/IRTG/MLSC/Encode-the-Qode/data/pretrained/analysis_report_CodeT5-test-12-300-4-2023-09-26-v2/results/checkpoint-88488\""]},{"cell_type":"code","execution_count":8,"metadata":{"id":"FRHaw5S7X81D"},"outputs":[],"source":["import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9t6d_nrX_lyy"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1322: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  warnings.warn(\n"]}],"source":["model = AutoModelWithLMHead.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name, skip_special_tokens=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZoeldwQcIkFZ"},"outputs":[],"source":["def generate_summary(test_samples, model, tokenizer, encoder_max_length):\n","    inputs = tokenizer(\n","        test_samples[\"input_sequence\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=encoder_max_length,\n","        return_tensors=\"pt\",\n","    )\n","    input_ids = inputs.input_ids.to(model.device)\n","    attention_mask = inputs.attention_mask.to(model.device)\n","    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length =150)\n","    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    return outputs, output_str"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sC67g4yM6hV6"},"outputs":[],"source":["def batch_tokenize_preprocess(batch,\n","                              tokenizer,\n","                              max_input_length,\n","                              max_output_length):\n","\n","    source = batch[\"input_sequence\"]\n","    target = batch[\"output_sequence\"]\n","\n","    source_tokenized = tokenizer(\n","        source,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_input_length\n","    )\n","\n","    target_tokenized = tokenizer(\n","        target,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_output_length\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","\n","    # Ignore padding in the loss\n","\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","\n","    return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGzD5nZ96ql_"},"outputs":[],"source":["encoder_max_length = 512\n","decoder_max_length = 300"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hP5f8PEc5qJe"},"outputs":[],"source":["test_dataset = load_dataset(\"json\",\n","                            data_files='test_dataset_20231007.json',\n","                            field=\"data\",\n","                            data_dir='../../data/preprocessed/Quantlet/no_context/')\n","\n","\n","validation_data_txt = test_dataset['train']\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch,\n","        tokenizer=tokenizer,\n","        max_input_length=encoder_max_length,\n","        max_output_length=decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XX0g8axk6huo"},"outputs":[],"source":["# SUBSAMPLE FOR GENERATION BEFORE TUNING\n","test_samples = validation_data_txt.select(range(20))\n","summaries_before_tuning = generate_summary(test_samples,\n","                                            model,\n","                                            tokenizer,\n","                                            encoder_max_length)[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BhQORzUP8Fd_"},"outputs":[],"source":["rouge = evaluate.load('rouge')\n","bleu = evaluate.load('bleu')\n","\n","references = test_samples['output_sequence']\n","predictions = summaries_before_tuning\n","results = rouge.compute(predictions=predictions, references=references)\n","\n","bleu = bleu.compute(predictions=predictions, references=references)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLRXM35V9DmS"},"outputs":[],"source":["validation_data_txt['output_sequence']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fsbDqTl8pqW"},"outputs":[],"source":["# loading the model you previously trained\n","model = AutoModelForSequenceClassification.from_pretrained(OUTPUT_DIR)\n","\n","# arguments for Trainer\n","test_args = TrainingArguments(\n","    output_dir = OUTPUT_DIR,\n","    do_train = False,\n","    do_predict = True,\n","    per_device_eval_batch_size = BATCH_SIZE,   \n","    dataloader_drop_last = False    \n",")\n","\n","# init trainer\n","trainer = Trainer(\n","            model = model, \n","            args = test_args, \n","            compute_metrics = compute_metrics)\n","\n","test_results = trainer.predict(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xnh_Lhg8kZX"},"outputs":[],"source":["bleu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EalmOChG8VCS"},"outputs":[],"source":["results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mBxRN9-U7Ild"},"outputs":[],"source":["test_samples['output_sequence']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"omaB3dDt607c"},"outputs":[],"source":["summaries_before_tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXXmByV261EO"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM4Hr9k83UY5HSTUyHOKG4Q","gpuType":"A100","machine_shape":"hm","mount_file_id":"1KmVoyMPZSwzHSRWIrLeTrINehi2VHCt1","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
