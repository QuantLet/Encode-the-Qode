{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JZal6ahJZQBU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%pip install protobuf==3.20.1\n",
    "%pip install transformers[torch]\n",
    "%pip install -q sentencepiece\n",
    "%pip install datasets==2.13.1\n",
    "%pip install evaluate\n",
    "%pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O5Mlzgdzaliu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "QPATH = \"Quantlet/4-qode2desc\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iaAT_m3NaEzp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.chdir(\n",
    "        f\"/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}\"\n",
    "    )\n",
    "else:\n",
    "    %load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oRmp1O7SZgaI",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/RDC/zinovyee.hub/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import torch, gc\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import importlib\n",
    "import analysis_modules\n",
    "\n",
    "importlib.reload(analysis_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_name(analysis_config):\n",
    "    name = analysis_config[\"model_name\"]\n",
    "    if \"checkpoint\" in name:\n",
    "        name = name.split(\"/\")[-1]\n",
    "    mode = analysis_config[\"MODE\"]\n",
    "    date = analysis_config[\"DATE\"]\n",
    "    if analysis_config[\"val_data_name\"].startswith(\"val\"):\n",
    "        sample = \"val\"\n",
    "    else:\n",
    "        sample = \"test\"\n",
    "    return f\"{name}_{mode}_{sample}_{date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeT5_no_context_test_20231024_random\n"
     ]
    }
   ],
   "source": [
    "analysis_config = {\n",
    "    \"DATE\": \"20231024_random\",\n",
    "    \"MODE\": \"no_context\",\n",
    "    \"model_name\": \"CodeT5\",\n",
    "    \"encoder_max_length\": 512,\n",
    "    \"decoder_max_length\": 75,\n",
    "    \"random_state\": 42,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"epochs\": 4,\n",
    "    \"train_batch\": 16,\n",
    "    \"eval_batch\": 4,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"logging_stes\": 100,\n",
    "    \"save_total_lim\": 1,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"label_smooting\": 0.1,\n",
    "    \"predict_generate\": True,\n",
    "    \"load_best_model_at_end\": False,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "}\n",
    "if analysis_config[\"MODE\"] == \"domain\":\n",
    "    analysis_config[\n",
    "        \"train_data_path\"\n",
    "    ] = f\"../../data/preprocessed/Quantlet/{analysis_config['DATE']}/no_context/\"\n",
    "else:\n",
    "    analysis_config[\n",
    "        \"train_data_path\"\n",
    "    ] = f\"../../data/preprocessed/Quantlet/{analysis_config['DATE']}/{analysis_config['MODE']}/\"\n",
    "\n",
    "analysis_config[\"train_data_name\"] = (\n",
    "    f\"full_train_dataset_{analysis_config['DATE']}_sample0.json\",\n",
    ")\n",
    "if analysis_config[\"MODE\"] == \"domain\":\n",
    "    analysis_config[\n",
    "        \"val_data_path\"\n",
    "    ] = f\"../../data/preprocessed/Quantlet/{analysis_config['DATE']}/no_context/\"\n",
    "else:\n",
    "    analysis_config[\n",
    "        \"val_data_path\"\n",
    "    ] = f\"../../data/preprocessed/Quantlet/{analysis_config['DATE']}/{analysis_config['MODE']}/\"\n",
    "analysis_config[\n",
    "    \"val_data_name\"\n",
    "] = f\"test_dataset_{analysis_config['DATE']}_sample0.json\"\n",
    "analysis_config[\"analysis_name\"] = create_name(analysis_config)\n",
    "print(analysis_config[\"analysis_name\"])\n",
    "\n",
    "if analysis_config[\"MODE\"] == \"domain\":\n",
    "    if analysis_config[\"model_name\"] == \"CodeT5\":\n",
    "        analysis_config[\n",
    "            \"model_name\"\n",
    "        ] = \"../../data/pretrained/analysis_report_CodeT5-test-12-300-4-2023-09-26-v2/results/checkpoint-88488\"\n",
    "    if analysis_config[\"model_name\"] == \"CodeTrans\":\n",
    "        analysis_config[\n",
    "            \"model_name\"\n",
    "        ] = \"../../data/pretrained/CodeTrans/results/checkpoint-12290\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "FRHaw5S7X81D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeT5_no_context_test_20231024_random\n",
      "cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-3535fc3383b9eb5b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3341073fb34d44e49e59522908294549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-11a49e64bc122c30/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc14a4238cd4033a388bb36980b2dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-3535fc3383b9eb5b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fb89e10981646399.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-11a49e64bc122c30/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e188d1a3da94ec7e.arrow\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      6.186         0.15        0.044        0.129           0.134   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.007        12.373  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='85' max='1088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  85/1088 00:52 < 10:38, 1.57 it/s, Epoch 0.31/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = analysis_modules.scs_analyze(**analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "smrdGzzNyo5n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_logs(trainer):\n",
    "    log_history = trainer.state.log_history\n",
    "    train_log = pd.DataFrame(columns=log_history[0].keys())\n",
    "    eval_log = pd.DataFrame(columns=log_history[1].keys())\n",
    "    for log in log_history:\n",
    "        if \"loss\" in log:\n",
    "            train_log = pd.concat(\n",
    "                [train_log, pd.DataFrame.from_dict(log, orient=\"index\").T], axis=0\n",
    "            )\n",
    "        elif \"eval_loss\" in log:\n",
    "            eval_log = pd.concat(\n",
    "                [eval_log, pd.DataFrame.from_dict(log, orient=\"index\").T], axis=0\n",
    "            )\n",
    "\n",
    "    logs = train_log.merge(\n",
    "        eval_log,\n",
    "        how=\"inner\",\n",
    "        left_on=[\"epoch\", \"step\"],\n",
    "        right_on=[\"epoch\", \"step\"],\n",
    "    )\n",
    "    return logs[\n",
    "        [\n",
    "            \"epoch\",\n",
    "            \"loss\",\n",
    "            \"step\",\n",
    "            \"eval_loss\",\n",
    "            \"eval_rouge1\",\n",
    "            \"eval_rouge2\",\n",
    "            \"eval_rougeL\",\n",
    "            \"eval_rougeLsum\",\n",
    "            \"eval_gen_len\",\n",
    "            \"eval_bleu\",\n",
    "            \"eval_brevity_penalty\",\n",
    "            \"eval_length_ratio\",\n",
    "            \"eval_translation_length\",\n",
    "            \"eval_reference_length\",\n",
    "        ]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = parse_logs(trainer).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge1</th>\n",
       "      <th>eval_rouge2</th>\n",
       "      <th>eval_rougeL</th>\n",
       "      <th>eval_rougeLsum</th>\n",
       "      <th>eval_gen_len</th>\n",
       "      <th>eval_bleu</th>\n",
       "      <th>eval_brevity_penalty</th>\n",
       "      <th>eval_length_ratio</th>\n",
       "      <th>eval_translation_length</th>\n",
       "      <th>eval_reference_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.3125</td>\n",
       "      <td>272.0</td>\n",
       "      <td>4.558359</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>0.2417</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>17.5673</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>6239.0</td>\n",
       "      <td>13072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.3069</td>\n",
       "      <td>544.0</td>\n",
       "      <td>3.833143</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>17.5652</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.4663</td>\n",
       "      <td>6096.0</td>\n",
       "      <td>13072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6604</td>\n",
       "      <td>816.0</td>\n",
       "      <td>3.497112</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2997</td>\n",
       "      <td>0.3069</td>\n",
       "      <td>17.9400</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.3386</td>\n",
       "      <td>0.4801</td>\n",
       "      <td>6276.0</td>\n",
       "      <td>13072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.3564</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>3.403933</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.1828</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>17.9938</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>0.4780</td>\n",
       "      <td>6249.0</td>\n",
       "      <td>13072.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    loss    step  eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  \\\n",
       "0    1.0  5.3125   272.0   4.558359       0.2856       0.1107       0.2417   \n",
       "1    2.0  4.3069   544.0   3.833143       0.3162       0.1467       0.2741   \n",
       "2    3.0  3.6604   816.0   3.497112       0.3382       0.1720       0.2997   \n",
       "3    4.0  3.3564  1088.0   3.403933       0.3462       0.1828       0.3082   \n",
       "\n",
       "   eval_rougeLsum  eval_gen_len  eval_bleu  eval_brevity_penalty  \\\n",
       "0          0.2538       17.5673     0.0354                0.3345   \n",
       "1          0.2849       17.5652     0.0550                0.3184   \n",
       "2          0.3069       17.9400     0.0700                0.3386   \n",
       "3          0.3167       17.9938     0.0750                0.3356   \n",
       "\n",
       "   eval_length_ratio  eval_translation_length  eval_reference_length  \n",
       "0             0.4773                   6239.0                13072.0  \n",
       "1             0.4663                   6096.0                13072.0  \n",
       "2             0.4801                   6276.0                13072.0  \n",
       "3             0.4780                   6249.0                13072.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPZowVhs+ksZzaIPG80pu3+",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "119XCh3Q64Zw4MGlsZQuGrMLS78o5MeWS",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "encode_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
