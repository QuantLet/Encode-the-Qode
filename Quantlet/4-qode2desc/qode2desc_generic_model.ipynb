{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JZal6ahJZQBU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "QPATH = \"Quantlet/4-qode2desc\"\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.chdir(\n",
    "        f\"/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}\"\n",
    "    )\n",
    "\n",
    "#%%capture\n",
    "#%pip install protobuf==3.20.1\n",
    "if IN_COLAB:\n",
    "    %pip install transformers[torch]\n",
    "    %pip install -q sentencepiece\n",
    "    %pip install datasets==2.13.1\n",
    "    %pip install evaluate\n",
    "    %pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iaAT_m3NaEzp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oRmp1O7SZgaI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import torch, gc\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import importlib\n",
    "import analysis_modules\n",
    "\n",
    "importlib.reload(analysis_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/flan-t5-base_no_context_val_20231119_normal\n",
      "google/flan-t5-base_no_context_val_20231119_normal\n",
      "cuda\n",
      "cuda\n",
      "Downloading and preparing dataset json/default to /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-c5a9527b5a04f930/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdd167799d14bbba7e26b7a036f8a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b327a459774168bc16caae037fde23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb4ed7286cb4b1faba33d447071dde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-c5a9527b5a04f930/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afda29ba6ca4d4d913c05a429beba94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-2efbf484d7e56e98/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b72057bd6a4ecc810bf331e1206712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c703dc1ace34766ac5507cd3a915bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfde0f9e8db2443a8d26c4f80d176484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/RDC/zinovyee.hub/.cache/huggingface/datasets/json/default-2efbf484d7e56e98/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a40651e4e145e6a61098505392e3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fb26c0dee347339dfdef24c62c3d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be09bba8756640afbc8c1b2c0f48ebaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='154' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 02:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      5.518        0.035        0.009        0.032           0.033   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.005        18.816  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10260' max='10260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10260/10260 28:05, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.493300</td>\n",
       "      <td>4.062862</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>17.580300</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>3427</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.870900</td>\n",
       "      <td>3.864535</td>\n",
       "      <td>0.286700</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>17.534400</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.329500</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>3526</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.532300</td>\n",
       "      <td>3.744955</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.124900</td>\n",
       "      <td>0.259700</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>18.016400</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>3704</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.271200</td>\n",
       "      <td>3.675475</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.274100</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>18.150800</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>3747</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.080400</td>\n",
       "      <td>3.638862</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>17.777000</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>3668</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.934900</td>\n",
       "      <td>3.606451</td>\n",
       "      <td>0.313200</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>18.213100</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.510700</td>\n",
       "      <td>3800</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.806800</td>\n",
       "      <td>3.599224</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>18.249200</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>3888</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.693300</td>\n",
       "      <td>3.570609</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.294400</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>18.108200</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>3731</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.612000</td>\n",
       "      <td>3.573540</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>18.416400</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.389500</td>\n",
       "      <td>0.514700</td>\n",
       "      <td>3830</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.533700</td>\n",
       "      <td>3.595254</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>18.013100</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>3851</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.475700</td>\n",
       "      <td>3.561934</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>18.249200</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.404700</td>\n",
       "      <td>0.525100</td>\n",
       "      <td>3907</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.424600</td>\n",
       "      <td>3.567132</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>18.180300</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.524900</td>\n",
       "      <td>3906</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.382600</td>\n",
       "      <td>3.572381</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.189100</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>18.278700</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.514900</td>\n",
       "      <td>3831</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.352500</td>\n",
       "      <td>3.565695</td>\n",
       "      <td>0.340200</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>18.134400</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.380200</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>3783</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.334500</td>\n",
       "      <td>3.571454</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.311100</td>\n",
       "      <td>0.315400</td>\n",
       "      <td>18.226200</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>3812</td>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  \\\n",
      "0      3.571        0.343        0.193        0.311           0.315   \n",
      "\n",
      "   eval_bleu  eval_gen_len  \n",
      "0      0.102        18.226  \n",
      "__________\n",
      "Original: Generates plots of energy consumption/production/both time series of energy consumers/prosumers generated from energy readings in 3-minute intervals.\n",
      "\n",
      "\n",
      "Summary before Tuning: a) Plot all consumers datasets = colnames(data)[-1] b) Plot exemplary consumption time series (5 with large 0 shares + 2 normal) datasets = c(\"c013 cons\", \"c035 cons\", \"c067 cons\", \"c070 cons\", c) Plot consumers\n",
      "\n",
      "\n",
      "Summary after Tuning: Plots the data with which the consumption or production values are plotted\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Scrape the Etherscan API to get source code of smart contracts given the list of their hashes\n",
      "\n",
      "\n",
      "Summary before Tuning: np.array('array(')')\n",
      "\n",
      "\n",
      "Summary after Tuning: This Quantlet contains 1 quantlet containing the raw data for the API token. It contains the raw data for the API token. It is in the root directory of the Quantlet.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'hfhd_dataclean code conducts pre-averaging estimation and match the \t\t\t   price and size intensity in a intermediate interval, solves the\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all= T)) library(inline) library( Rcpp) src-' using namespace std; vectordouble> ts1=asvectordouble> >(ts0); double freq=asdouble> (f\n",
      "\n",
      "\n",
      "Summary after Tuning: Calculates the number of limit order book within each time interval the length of time interval can be set by the user.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'hfhd_tvnet code plots the time-varying full-sample\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all= T)) graphics.off() setwd(\"\") load(\"mydate. R Data\") load(\" GIR 30s. R Data\") for fullconnectedness4. R Data = \"\" for fullconnectedness4. R Data = \"\" for fullconnectedness4. R Data = \"\" for\n",
      "\n",
      "\n",
      "Summary after Tuning: 'hfhd_rob code plots the time series of the bootstrapped Ethereum Blockchain\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Obtains estimations of parameters involved in the normal-Laplace contaminations by expectation-maximization  algorithm\n",
      "Gives estimations of VaR and ES by historical simulations, based on the Laplace distribution and mixed model. Shows the tails of log returns of CRIX\n",
      "during 2014.04-2018.01 is heavier than that before, and the approximation based on Laplace at scaled level performs well\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list = ls(all = TRUE)) install packages libraries = c(\"ggplot2\", \"dplyr\", \"reshape2\") lapply(libraries, function(x)) if (!(x %in% installed.packages)) install packages libraries =\n",
      "\n",
      "\n",
      "Summary after Tuning: Estimates the VaR and ES with input parameters given by estimation.epsilon.mu.std \n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Cumulative return of the different cores with an initial investment of 1 dollar\n",
      "\n",
      "\n",
      "Summary before Tuning: y = \"core\", mode=\"lines\", line = list(color = 'rgb(0, 0, 0)'))%> )\n",
      "\n",
      "\n",
      "Summary after Tuning: Cumulative return of the Core and the NASDAQ and DAX 30 for the SP500 and DAX 30 respectively.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Plots the Correlation of an index, here CORE, against crypto currencies\n",
      "\n",
      "\n",
      "Summary before Tuning: a = matrix(rep(0,2*83),ncol=83) colnames(a) = colnames(data cryptos 84 sp500) rownames(a) = c(\" Shapiro Statisitc\",\"p-value\") for (i in 1 : 83) \n",
      "\n",
      "\n",
      "Summary after Tuning: Correlation of cryptos with core and core cryptos is performed on a standard normality test.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Identifies valid URLs for the articles and downloads and saves the full PDFs of all publications from the CRC 649 website.\n",
      "\n",
      "\n",
      "Summary before Tuning: UR Ls and create names for the pdfs: fromhere = paste0(\"https://sfb649.wiwi.hu-berlin.de/papers/pdf/ SFB649 DP\", table info number, \".pdf\", sep = \"\") Set the directory to the location where the PD\n",
      "\n",
      "\n",
      "Summary after Tuning: Scrapes the pagination of all corresponding CRC 649 papers.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: computes the Jaccard, simple matching and Tanimoto proximity coefficients for binary car data\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all= TRUE)) graphics.off()                            \n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs cluster analysis for car data. The plot shows the first two principal components in two-dimensional scatterplots. The second plot shows the first two principal components in two-dimensional scatterplots.'\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Performs a cluster analysis for the US cereal data from the R-package MASS. On the transformed data will be performed a principal component analysis and a cluster analysis employing Euclidean distance with the Ward linkage algorithm. Plots of principal components and the dendrogram are presented. After extraction of 3 clusters, the principal components with the 3 clusters  are shown\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all= TRUE)) graphics.off() install.packages(\" MASS\") library(MASS) cereal = matrix(c(U Scereal calories, U Scereal protein, U Scereal fat, U Scereal sugars), nrow = length( U Sce\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs a PCA for the standardized US cereal data and shows the first two principal components for the individuals and the variables. The normalization corresponds to that of Lebart/Morineau/Fenelon.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Employs the centroid linkage using squared Euclidean distance matrices to perform a cluster analysis on an 8 points example\n",
      "\n",
      "\n",
      "Summary before Tuning: import numpy as np import matplotlib.pyplot as plt from matplotlib.patches import elipse from scipy.cluster import hierarchy eight = np.array(([-3, -2, 1, 2, 4, 4, 2, -4, -3])). T\n",
      "\n",
      "\n",
      "Summary after Tuning: Performs cluster analysis for 8 data points.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Employs the centroid linkage using squared Euclidean distance matrices to perform a cluster analysis on an 8 points example\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all= TRUE)) install.packages(\"car\") library(car) define eight points eight = cbind(c(-3,-2,-2,-2,1,1,2,4),c(0,4,-1,-2,4,2,-4,-3)) eight = eight[c(8,7\n",
      "\n",
      "\n",
      "Summary after Tuning: 'employs the single linkage method using squared Euclidean distance matrices to perform a cluster analysis on an 8 points example\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a lasso logit regression on the car data.'\n",
      "\n",
      "\n",
      "Summary before Tuning: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs a logit regression for the car data set. Plots the LASSO regression for the car data set. Performing the logit regression. Performing the logit regression.\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Applies the sliced inverse regression algorithm  on car data set  for dimension reduction.'\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all= TRUE)) graphics.off() m.text = row.names(carc) n = nrow(carc) get rid of the outliers keep = 1:n; x = carc[keep,c(2,(5:12))]; type\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs the Penalized Adaptive Method, a combination of propagation-separation approach and a SIR-SIR penalty, to fit a model to a simulated data set.'\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a test of independence for French baccalaurent data'\n",
      "\n",
      "\n",
      "Summary before Tuning: clear memory and close windows clear all clc SM Schi2bac test of independence for french baccalaureat data [type, A, B, C, D, E, F, G, H] = textread('bac.dat',' s f f'); bac = [type, A,\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Performs a standardized regression to the French baccalaureat data for the test of independence for the French baccalauréat.'\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Performs a test of independence for French baccalaurent data'\n",
      "\n",
      "\n",
      "Summary before Tuning: clear memory and close windows rm(list=ls(all= TRUE)) graphics.off() load(\"bac.rda\")\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Computes the 2D map of the points of interest of the S&P 500 companies. The data is taken from the'sandwich' folder.'\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Computes boxplots for the mileage of US, Japanese and European company headquarters from car data, respectively. Evidently, for the US the core of observations have lowest values of mileage compared with Japan and the EU. However, the US shows larger variation in the data. All boxplots show rather unsymmetric boxes, the medians  and means  are not overlapping.'\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all= TRUE)) remove variables graphics.off() close all windows setwd(\" C/...\") set working direktory\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Computes a linear regression of mileage on mileage for car data.'\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: 'Computes boxplots for the mileage of US, Japanese and European company headquarters from car data, respectively. Evidently, for the US the core of observations have lowest values of mileage compared with Japan and the EU. However, the US shows larger variation in the data. All boxplots show rather unsymmetric boxes, the medians  and means  are not overlapping.'\n",
      "\n",
      "\n",
      "Summary before Tuning: -Paints -dpng -r600 SM Sboxcar.png\n",
      "\n",
      "\n",
      "Summary after Tuning: 'Computes the 2D map of US, Japanese, and European cities by application of multidimensional scaling. nM_txt'\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Computes normalized principal components for US crime data set which consists of the reported number of crimes in the 50 US states in 1985. The crimes were classified according to 7 categories: murder, rape, robbery, assault, burglary, larceny, and auto theft. The data set also contains identification of the resion: Northeast, Midwest, South, West. After scaling the variables, a NPCA is perfomed the reported felonies. A scatterplot of the first two principal components, a screeplot and a plot of the correlations of the first two PCs with the original variables.\n",
      "\n",
      "\n",
      "Summary before Tuning: ucircle = [cos((0:360)/180*3.14159)', sin((0:360)/180*3.14159)']; Screeplot figure(2); bar(latent) = []; ucircle = [cos((0:360)/180*3.1\n",
      "\n",
      "\n",
      "Summary after Tuning: 'performs a PCA for the standardized US crime data set. The first one is dedicated to the 'performs a PCA for the standardized US crime data set.'\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "__________\n",
      "Original: Computes normalized principal components for US crime data set which consists of the reported number of crimes in the 50 US states in 1985. The crimes were classified according to 7 categories: murder, rape, robbery, assault, burglary, larceny, and auto theft. The data set also contains identification of the resion: Northeast, Midwest, South, West. After scaling the variables, a NPCA is perfomed the reported felonies. A scatterplot of the first two principal components, a screeplot and a plot of the correlations of the first two PCs with the original variables.\n",
      "\n",
      "\n",
      "Summary before Tuning: rm(list=ls(all= TRUE)) graphics.off() setwd(\" C:/...\") set working directory load(\"uscrime.rda\") print(pccrime) eigenvalues of the variance matrix pccrime sdev2 opar = par(\n",
      "\n",
      "\n",
      "Summary after Tuning: 'performs a PCA for the standardized US crime data.'\n",
      "\n",
      "\n",
      "__________\n",
      "\n",
      "\n",
      "\n",
      "Analysis finished\n"
     ]
    }
   ],
   "source": [
    "for MODEL in [\"google/flan-t5-base\"]:   #'CodeTrans',\n",
    "    for SAMPLE_MODE in ['val']:#'val',\n",
    "        if SAMPLE_MODE=='test':\n",
    "            train_name = 'full_train'\n",
    "            test_name  = 'test'\n",
    "        elif SAMPLE_MODE=='val':\n",
    "            train_name = 'train'\n",
    "            test_name  = 'val'\n",
    "        else: \n",
    "            print('Only test and val are available. Please change the SAMPLE_MODE')\n",
    "        \n",
    "        analysis_config = {\n",
    "            \"DATE\": \"20231119_normal\",\n",
    "            \"MODE\": \"no_context\",\n",
    "            \"model_name\": MODEL,\n",
    "            \"encoder_max_length\": 512,\n",
    "            \"decoder_max_length\": 75,\n",
    "            \"random_state\": 42,\n",
    "            \"learning_rate\": 5e-4,\n",
    "            \"epochs\": 15,\n",
    "            \"train_batch\": 4,\n",
    "            \"eval_batch\": 4,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.1,\n",
    "            \"logging_stes\": 100,\n",
    "            \"save_total_lim\": 1,\n",
    "            \"save_strategy\": \"epoch\",\n",
    "            \"label_smooting\": 0.1,\n",
    "            \"predict_generate\": True,\n",
    "            \"load_best_model_at_end\": False,\n",
    "            \"evaluation_strategy\": \"epoch\",\n",
    "            \"freeze\": True,\n",
    "        }\n",
    "        \n",
    "        analysis_config[\"train_data_path\"] = f\"../../data/preprocessed/Quantlet/{analysis_config['DATE']}/{analysis_config['MODE']}/\"\n",
    "        analysis_config[\"train_data_name\"] = f\"{train_name}_dataset_{analysis_config['DATE']}_sample0.json\"\n",
    "        \n",
    "        analysis_config[\"val_data_path\"] = f\"../../data/preprocessed/Quantlet/{analysis_config['DATE']}/{analysis_config['MODE']}/\"\n",
    "        analysis_config[\"val_data_name\"] = f\"{test_name}_dataset_{analysis_config['DATE']}_sample0.json\"\n",
    "\n",
    "        analysis_config[\"analysis_name\"] = analysis_modules.create_name(analysis_config)\n",
    "        \n",
    "        print(analysis_config[\"analysis_name\"])\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        trainer = analysis_modules.scs_analyze(**analysis_config)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        logs = analysis_modules.parse_logs(trainer).drop_duplicates()\n",
    "\n",
    "        ANALYSIS_FOLDER=f'reports/analysis_report_{analysis_config[\"analysis_name\"]}'\n",
    "\n",
    "        logs.to_csv(f'{ANALYSIS_FOLDER}/logs.csv', index=False)\n",
    "\n",
    "        print('Analysis finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n"
     ]
    }
   ],
   "source": [
    "print('check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPZowVhs+ksZzaIPG80pu3+",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "119XCh3Q64Zw4MGlsZQuGrMLS78o5MeWS",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
