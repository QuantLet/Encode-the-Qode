{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas==1.3.5 # for comaparability woth colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > session_info_sunflower.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'traverse_and_parse' from '/usr/net/zinovyee.hub/IRTG/Encode-the-Qode/Quantlet/2-Parse-Quantlets-Folders/traverse_and_parse.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pickle \n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "from datetime import date\n",
    "\n",
    "import importlib\n",
    "sys.path.append('../3-data-preprocessing')\n",
    "import preprocessing_utils\n",
    "importlib.reload(preprocessing_utils)\n",
    "\n",
    "import traverse_and_parse as tp\n",
    "importlib.reload(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PATHS \n",
    "PATH_TO_PARSE = '../../data/QuantLet'\n",
    "FILE_TYPES = ['m', 'py', 'r', 'R', 'M', 'ipynb']\n",
    "TEST_PATH = '../data/Q_test'\n",
    "\n",
    "# CONSTANTS\n",
    "IPY_CONVERT = False\n",
    "\n",
    "# VARIABLE PARAMETERS\n",
    "TODAY = '20231014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if IPY_CONVERT:\n",
    "    # q_name, folder_name, code_script, type_script, metainfo_file\n",
    "    language, name = '', ''\n",
    "    for i, (root, directories, files) in enumerate(os.walk(PATH_TO_PARSE)):\n",
    "        \n",
    "        \n",
    "        for file in files:\n",
    "            language = file.split('.')[-1]\n",
    "            \n",
    "            if (language == 'ipynb'):\n",
    "                if not os.path.exists(f\"{root}/{file.replace('ipynb', 'py')}\"):\n",
    "                    print(file)\n",
    "                    os.popen(f\"jupyter nbconvert --to python {root}/{file}\")\n",
    "            else:\n",
    "                continue    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19214it [01:24, 226.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4867, 5)\n",
      "(4864, 5)\n",
      "(4837, 6)\n"
     ]
    }
   ],
   "source": [
    "output = tp.traverse_folder(PATH_TO_PARSE, FILE_TYPES)\n",
    "repos = tp.prepare_repos_df(output['repos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4837, 6)\n"
     ]
    }
   ],
   "source": [
    "repos.type_script = repos.type_script.str.lower()\n",
    "repos = repos[repos.type_script.isin(\n",
    "            ['py', 'r', 'm', 'ipynb']\n",
    "        )\n",
    "    ]\n",
    "repos_df = repos[~repos.folder_name.str.contains('.ipynb_checkpoints')]\n",
    "repos_df.loc[repos_df.type_script== 'ipynb', 'type_script']='py'\n",
    "repos_df = repos_df.reset_index(drop=True)\n",
    "print(repos_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME = f'../../data/preprocessed/Quantlet/{TODAY}/Quantlets_{TODAY}'\n",
    "with open(f'{NAME}.pkl', 'wb') as file:\n",
    "    pickle.dump(repos_df, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encode_code",
   "language": "python",
   "name": "encode_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
