{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1wlGOOqN6HqI_4DtMDWwVViv1NPV1i_dd","authorship_tag":"ABX9TyMrn51B2B/tlyLeTR9FfngK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fLZ-fhNrroEm"},"outputs":[],"source":["%%capture\n","%pip install torchtext==0.6.0\n","%pip install transformers\n","%pip install evaluate\n","%pip install rouge_score"]},{"cell_type":"code","source":["QPATH = 'Quantlet/4-seq2seq'\n","\n","import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","import os\n","if IN_COLAB:\n","  os.chdir(f'/content/drive/MyDrive/ColabNotebooks/IRTG/Encode_the_Qode/Encode-the-Qode/{QPATH}')"],"metadata":{"id":"PyN2kYYirokB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchtext\n","torchtext.__version__"],"metadata":{"id":"CiqTfZxrA5oD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import pandas as pd\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","from tqdm import tqdm\n","\n","import re\n","import pickle\n","\n","#from torchtext import data, datasets\n","#import torchdata.datapipes as dp\n","#import torchtext.transforms as T\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.data import DataLoader\n","from torchtext.datasets import TranslationDataset, Multi30k\n","from torchtext.data import Field, BucketIterator, TabularDataset\n","\n","import spacy\n","\n","import random\n","import math\n","import time\n","\n","import importlib\n","from seq2seq_modeling import *\n","from seq2seq_modeling import Seq2Seq,  epoch_time # train,\n","#from seq2seq_modeling import  evaluate as ev\n","from transformers import AutoTokenizer"],"metadata":{"id":"u8WwMU8xA7D8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""],"metadata":{"id":"yWc5RB1VA8no"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATE = '20231104'"],"metadata":{"id":"34hZSDQjA-4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_summary(text):\n","    \"\"\"\n","    Tokenizes question from a string into a list of strings (tokens) and reverses it\n","    \"\"\"\n","    return list(filter(lambda x: len(x) < 15, re.findall(r\"[\\w']+\", text)))#[::-1]\n","\n","def tokenize_snippet(text):\n","    \"\"\"\n","    Tokenizes code snippet into a list of operands\n","    \"\"\"\n","    return list(filter(lambda x: (len(x) < 15) and (len(x)>=2), re.findall(r\"[\\w']+|[.,!?;:@~(){}\\[\\]+-/=\\\\\\'\\\"\\`]\", ' '.join(text.split()[:500]))))"],"metadata":{"id":"gcq89WX2BAJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SRC = Field(\n","    tokenize = tokenize_snippet,\n","    init_token = '<sos>',\n","    eos_token = '<eos>',\n","    lower = True,\n","    include_lengths = True\n",")\n","\n","TRG = Field(\n","    tokenize = tokenize_summary,\n","    init_token = '<sos>',\n","    eos_token = '<eos>',\n","    lower = True\n",")\n","\n","fields = {\n","    'code_script': ('src', SRC),\n","    'Description': ('trg', TRG)\n","}\n","\n","train_data, valid_data, test_data = TabularDataset.splits(\n","                            path = f'../../data/preprocessed/Quantlet/{DATE}/',\n","                            train = f\"train_df_{DATE}_sample0.csv\",\n","                            validation = f\"val_df_{DATE}_sample0.csv\",\n","                            test = f\"test_df_{DATE}_sample0.csv\",\n","                            format = 'csv',\n","                            fields = fields\n",")"],"metadata":{"id":"9CHkc-LJBB-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SRC.build_vocab([train_data.src], max_size=30000, min_freq=4)\n","print(SRC.vocab.freqs.most_common(20))\n","\n","\n","TRG.build_vocab([train_data.trg], max_size=4000, min_freq=2)\n","print(TRG.vocab.freqs.most_common(20))\n","\n","print(f\"Unique tokens in code: {len(SRC.vocab)}\")\n","print(f\"Unique tokens in descriptions: {len(TRG.vocab)}\")"],"metadata":{"id":"6OGRkGdbBEZ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#device = torch.device('cpu')"],"metadata":{"id":"YaeFchIFBG0J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 4\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","        batch_size = BATCH_SIZE,\n","        sort_within_batch = True,\n","        sort_key = lambda x : len(x.src),\n","        device = device)"],"metadata":{"id":"RAVohJaGBIEn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 128\n","DEC_EMB_DIM = 128\n","ENC_HID_DIM = 100\n","DEC_HID_DIM = 50\n","ENC_DROPOUT = 0.8\n","DEC_DROPOUT = 0.3\n","PAD_IDX = SRC.vocab.stoi['<pad>']\n","SOS_IDX = TRG.vocab.stoi['<sos>']\n","EOS_IDX = TRG.vocab.stoi['<eos>']\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)"],"metadata":{"id":"9WF1KKMkBJdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'N Parameters {count_parameters(model):,}')"],"metadata":{"id":"xIwJk6XIBLDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.apply(init_weights)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"],"metadata":{"id":"iJCIOXDWQAm0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import evaluate\n","def compute_metrics(decoded_preds, decoded_labels, remove_special_tokens=False):\n","\n","        if remove_special_tokens:\n","          decoded_preds = [pred.replace('<eos>', '').replace('<sos>', '').replace('<unk>', '').replace('<pad>', '') for pred in decoded_preds]\n","          decoded_labels = [pred.replace('<eos>', '').replace('<sos>', '').replace('<unk>', '').replace('<pad>', '') for pred in decoded_labels]\n","\n","        results_dict = {}\n","        for m in ['rouge', 'bleu']:\n","            metric = evaluate.load(m)\n","\n","            if m=='bleu':\n","                result = metric.compute(\n","                    predictions=decoded_preds, references=decoded_labels\n","                )\n","            elif m=='rouge':\n","                result = metric.compute(\n","                    predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n","                )\n","            result = {key: value for key, value in result.items() if key!='precisions'}\n","\n","            result = {k: round(v, 4) for k, v in result.items()}\n","            results_dict.update(result)\n","        return results_dict"],"metadata":{"id":"a5lRE-t9BM5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_local(model, iterator, optimizer, criterion, clip, store=False):\n","\n","    rouge_list = []\n","    loss_list = []\n","    trans_list = []\n","    targets_list = []\n","\n","    model.train()\n","\n","    epoch_loss = 0\n","\n","    for i, batch in tqdm(enumerate(iterator)):\n","          src, src_len = batch.src\n","          trg = batch.trg\n","\n","          optimizer.zero_grad()\n","\n","          output, attention = model(src, src_len, trg, 0.4)\n","\n","          #trg = [trg sent len, batch size]\n","          #output = [trg sent len, batch size, output dim]\n","\n","          output = output[1:].view(-1, output.shape[-1])\n","          trg = trg[1:].view(-1)\n","\n","\n","          #trg = [(trg sent len - 1) * batch size]\n","          #output = [(trg sent len - 1) * batch size, output dim]\n","\n","          loss = criterion(output, trg)\n","\n","          loss.backward()\n","\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","          optimizer.step()\n","\n","          epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"],"metadata":{"id":"tWAUTn8zBOnA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ev(model, iterator, criterion, store=False):\n","\n","    #rouge_list = []\n","    #loss_list = []\n","    trans_list = []\n","    targets_list = []\n","\n","    model.eval()\n","\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","\n","        for i, batch in enumerate(iterator):\n","            src, src_len = batch.src\n","            trg = batch.trg\n","\n","            output, attention = model(src, src_len, trg, 0) #turn off teacher forcing\n","\n","            output = output[1:].view(-1, output.shape[-1])\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [trg sent len, batch size]\n","            #output = [trg sent len, batch size, output dim]\n","            loss = criterion(output, trg)\n","\n","            #trg = [(trg sent len - 1) * batch size]\n","            #output = [(trg sent len - 1) * batch size, output dim]\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"],"metadata":{"id":"4e8QlCkEBQMb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d_path = f'../../data/preprocessed/Quantlet/{DATE}/'\n","train_df = pd.read_csv(f\"{d_path}train_df_{DATE}_sample0.csv\")\n","validation_df = pd.read_csv(f\"{d_path}val_df_{DATE}_sample0.csv\")\n","test_df = pd.read_csv(f\"{d_path}test_df_{DATE}_sample0.csv\")"],"metadata":{"id":"ABabVVsSZ5dE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","tqdm.pandas()"],"metadata":{"id":"2GHNzhync_sH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_dict = {}\n","STORE = True\n","\n","results_dict_table = {}\n","\n","for SEED in range(7):\n","  print(SEED)\n","\n","  random.seed(SEED)\n","  torch.manual_seed(SEED)\n","  torch.backends.cudnn.deterministic = True\n","\n","  model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)\n","  model.apply(init_weights)\n","\n","  optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","  criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n","\n","  N_EPOCHS = 10\n","  CLIP = 1\n","\n","  best_valid_loss = float('inf')\n","\n","  training_rouge = []\n","  training_loss = []\n","\n","  evaluation_rouge = []\n","  evaluation_loss = []\n","\n","  for epoch in range(0, N_EPOCHS):\n","      print(epoch)\n","\n","      start_time = time.time()\n","\n","      print('TRAINING')\n","      train_loss = train_local(model, train_iterator, optimizer, criterion, CLIP)\n","      valid_loss = ev(model, valid_iterator, criterion)\n","\n","      # FULL VALIDATION\n","      print('VALIDATION TRAIN')\n","      train_df[f'pred_{epoch}'] = train_df.code_script.progress_apply(lambda x: translate_sentence(model, x)[0])\n","      print('VALIDATION VALIDATION')\n","      validation_df[f'pred_{epoch}'] = validation_df.code_script.progress_apply(lambda x: translate_sentence(model, x)[0])\n","      print('VALIDATION TEST')\n","      test_df[f'pred_{epoch}'] = test_df.code_script.progress_apply(lambda x: translate_sentence(model, x)[0])\n","\n","      end_time = time.time()\n","\n","      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","      if valid_loss < best_valid_loss:\n","          best_valid_loss = valid_loss\n","          torch.save(model.state_dict(), 'conala_model_attention_test.pt')\n","\n","      print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","      print(f'Perplexity (training): {math.exp(train_loss):7.3f}')\n","      #print(f'Perplexity (validation): {math.exp(valid_loss):7.3f}')\n","\n","      #print(f'Loss (training): {train_loss:7.3f}')\n","      #print(f'Loss (validation): {valid_loss:7.3f}')\n","\n","      #print(f'ROUGE (training): {train_rouge}')\n","      #print(f'ROUGE (validation): {eval_rouge}')\n","\n","  train_df.to_csv(f'../../data/preprocessed/Quantlet/{DATE}/train_with_epoch_preds_{SEED}.csv', index=False)\n","  validation_df.to_csv(f'../../data/preprocessed/Quantlet/{DATE}/val_with_epoch_preds.csv_{SEED}', index=False)\n","  test_df.to_csv(f'../../data/preprocessed/Quantlet/{DATE}/test_with_epoch_preds.csv_{SEED}', index=False)"],"metadata":{"id":"-LYUCLjGBQz_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df"],"metadata":{"id":"JnjLVZ_xje0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["compute_metrics(train_df['pred_0'].apply(lambda x: ' '.join(x)).values.tolist(), train_df['Description'])"],"metadata":{"id":"KtWk6kmCgG44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(f'../../data/preprocessed/Quantlet/{DATE}/results_dict_epochs.pickle', 'wb') as handle:\n","    pickle.dump(results_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"efWjsWN4CfIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(f'../../data/preprocessed/Quantlet/{DATE}/results_table_last.pickle', 'wb') as handle:\n","    pickle.dump(results_dict_table, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"C_e1KWoMY1_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_loss_last = []\n","val_rouge_last = []\n","\n","for run in range(7):\n","    val_rouge_last.append(results_dict[run]['evaluation_rouge'][-1])\n","    val_loss_last.append(results_dict[run]['evaluation_loss'][-1])"],"metadata":{"id":"5BskstjkFtU2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), f'../../data/preprocessed/Quantlet/{DATE}/conala_model_attention_test.pt')"],"metadata":{"id":"eacvcRfJFuGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(f'../../data/preprocessed/Quantlet/{DATE}/conala_model_attention_test.pt'))\n","\n","test_loss = ev(model, test_iterator, criterion)\n","\n","print(f'Perplexity (test): {math.exp(test_loss):7.3f}')\n","print(f'Loss (test): {test_loss:7.3f}')"],"metadata":{"id":"RjEfLgLoCFcn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def translate_sentence(model, sentence):\n","    global SRC\n","    global TRG\n","    model.eval()\n","    tokenized = tokenize_snippet(sentence)\n","    tokenized = ['<sos>'] + [t.lower() for t in tokenized] + ['<eos>']\n","    numericalized = [SRC.vocab.stoi[t] for t in tokenized]\n","    sentence_length = torch.LongTensor([len(numericalized)]).to(device)\n","    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device)\n","    translation_tensor_logits, attention = model(tensor, sentence_length, None, 0)\n","    translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1)\n","    translation = [TRG.vocab.itos[t] for t in translation_tensor]\n","    translation, attention = translation[1:], attention[1:]\n","    return translation, attention"],"metadata":{"id":"eGZxnErrCIJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_idx = 2\n","\n","src = ' '.join(vars(train_data.examples[example_idx])['src'])\n","trg = ' '.join(vars(train_data.examples[example_idx])['trg'])\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')\n","\n","translation, attention = translate_sentence(model, src)\n","\n","print('predicted trg = ', ' '.join(translation))\n","\n","#display_attention(src, translation, attention)"],"metadata":{"id":"coUolij1CKdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_idx = 2\n","\n","src = ' '.join(vars(test_data.examples[example_idx])['src'])\n","trg = ' '.join(vars(test_data.examples[example_idx])['trg'])\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')\n","\n","translation, attention = translate_sentence(model, src)\n","\n","print('predicted trg = ', ' '.join(translation))\n","\n","#display_attention(src, translation, attention)"],"metadata":{"id":"imTkjcipJMuQ"},"execution_count":null,"outputs":[]}]}