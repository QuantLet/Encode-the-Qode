{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct code to keywords generation with a code trained model\n",
    "\n",
    "In this notebook, related to the experiment 1: we investigate whether fine-tuning of a code model on our own corpus will help in code keywords generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.1 in /home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages (3.20.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install protobuf==3.20.1\n",
    "#%pip install -q transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'preprocessing_utils' from '/usr/net/zinovyee.hub/IRTG/Encode-the-Qode/Quantlet/code_description2project_description/../src/preprocessing_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import  DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import importlib\n",
    "import preprocessing_utils\n",
    "importlib.reload(preprocessing_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_Qs_file = '../../data/preprocessed/Quantlet/Parsed_Qs_19032023.pkl'\n",
    "dataset = preprocessing_utils.QuantletDataset(parsed_Qs_file)\n",
    "\n",
    "CLEAN_UP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1322: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=AutoModelWithLMHead.from_pretrained(\"SEBIS/code_trans_t5_large_source_code_summarization_python_multitask\")\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"SEBIS/code_trans_t5_large_source_code_summarization_python_multitask\",\n",
    "skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "# Step 6: Fine-tuning Training Loop\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rm(list = ls(all = TRUE))\\n',), ('wdir = \"/Users/annshchekina/Desktop/Kod/FRM_All\"\\n',), ('plot_labels = c(20190603, 20200101, 20200601)\\n',), ('channel = \"EM\"\\n',), ('tau = 0.50\\n',), ('s = 63\\n',), ('#Plot parameter defined based on the outliers\\n',), ('if (channel == \"Crypto\") {\\n',), ('  lambda_cutoff = 0.1359\\n',), ('  M_macro = 5} else \\n',), ('if (channel == \"EM\") {\\n',), ('  lambda_cutoff = 10\\n',), ('  M_macro = 12}\\n',), ('setwd(wdir)\\n',), ('if (tau == 0.05) input_path = paste0(\"Output/\", channel) else \\n',), ('  input_path = paste0(\"Output/\", channel, \"/Sensitivity/tau=\", 100*tau, \"/s=\", s)\\n',), ('output_path = input_path \\n',), ('#Check if package is installed, if not: install, either way: load \\n',), ('if (!require(igraph)) install.packages(\"igraph\"); library(igraph)\\n',), ('if (!require(qgraph)) install.packages(\"graph\"); library(qgraph)\\n',), ('if (!require(ggplot2)) install.packages(\"ggplot2\"); library(ggplot2)\\n',), ('if (!require(gganimate)) install.packages(\"gganimate\"); library(gganimate)\\n',), (\"if (!require(av)) install.packages('av'); library(av)\\n\",), ('if (!require(gifski)) install.packages(\"gifski\"); library(gifski)\\n',), ('if (!require(strex)) install.packages(\"strex\"); library(strex)\\n',), ('if (!require(magick)) install.packages(\"magick\"); library(magick)\\n',), ('if (!require(dplyr)) install.packages(\"dplyr\"); library(dplyr)\\n',), ('if (!require(matrixStats)) install.packages(\"matrixStats\"); library(matrixStats)\\n',), ('if (!require(tools)) install.packages(\"tools\"); library(tools)\\n',), ('#Set ggplot2 theme\\n',), ('theme_set(theme_classic())\\n',), ('#List of centrality types and their numbers\\n',), ('centralitylist = list(\"OutDegree\" = 1, \"InDegree\" = 2, \"Closeness\" = 3, \\n',), ('                      \"Betweenness\" = 4, \"InInfluence\" = 5, \"OutInfluence\" = 6)\\n',), ('#Read historical FRM index\\n',), ('FRM_index = read.csv(paste0(input_path, \"/Lambda/FRM_\", channel, \"_index.csv\"))\\n',), ('## Calculate centralities\\n',), ('#Create a list of files in the folder and extract dates from the names\\n',), ('file_list = list.files(path = paste0(input_path, \"/Adj_Matrices\"))\\n',), ('file_list = file_list[file_list!=\"Fixed\"]\\n',), ('dates = as.character(str_first_number(file_list), format = \"%Y%m%d\")\\n',), ('dates = as.Date(dates, format = \"%Y%m%d\")\\n',), ('N = length(file_list)\\n',), ('#Create a list of all network graphs\\n',), ('allgraphs = lapply(1:N, function(i) {\\n',), ('  data = read.csv(paste0(input_path, \"/Adj_Matrices/\", file_list[i]), row.names = 1)\\n',), ('  M_stock = ncol(data)-M_macro\\n',), ('  adj_matrix = data.matrix(data[1:M_stock, 1:M_stock])\\n',), ('  q = qgraph(adj_matrix, layout = \"circle\", details = TRUE, \\n',), ('                                   vsize = c(5,15), DoNotPlot = TRUE)\\n',), ('  return(q)\\n',), ('})\\n',), ('allcentralities = centrality(allgraphs)\\n',), ('eigencentrality = lapply(1:N, function(i) eigen_centrality(as.igraph(allgraphs[[i]]))$vector)\\n',), ('#Calculate averages\\n',), ('outdegree_avg = sapply(1:N, function(i) mean(allcentralities[[i]]$OutDegree))\\n',), ('indegree_avg = sapply(1:N, function(i) mean(allcentralities[[i]]$InDegree))\\n',), ('closeness_avg = sapply(1:N, function(i) mean(allcentralities[[i]]$Closeness))\\n',), ('betweenness_avg = sapply(1:N, function(i) mean(allcentralities[[i]]$Betweenness))\\n',), ('eigenvector_avg = sapply(1:N, function(i) mean(eigencentrality[[i]]))\\n',), ('#Restructure list into individual node centralities\\n',), ('outliers = which(FRM_index$FRM > lambda_cutoff)\\n',), ('## Plot FRM index vs all centralities\\n',), ('cent_plot = function(cent_type, lambda) {\\n',), ('  cent_string = deparse(substitute(cent_type))\\n',), ('  png(paste0(output_path, \"/Centrality/FRM_\", cent_string,\".png\"), \\n',), ('      width = 900, height = 600, bg = \"transparent\")\\n',), ('  par(mar = c(5, 4, 4, 4) + 0.3)\\n',), ('  plot(lambda[-outliers], type = \"l\", col = \"blue\", xlab = \"\", \\n',), ('       ylab = \"FRM index\", xaxt = \"n\", lwd = 2)\\n',), ('  par(new = TRUE)\\n',), ('  plot(cent_type[-outliers], type = \"l\", col = \"red\", axes = FALSE, \\n',), ('       xlab = \"\", ylab = \"\", xaxt = \"n\")\\n',), ('  axis(side = 4, at = pretty(range(cent_type[-outliers])))\\n',), ('  ll = which(FRM_index$date[-outliers] %in% plot_labels)\\n',), ('  axis(1, at = ll, labels = plot_labels)\\n',), ('  mtext(paste0(gsub(\"_.*\", \"\", cent_string) %>% toTitleCase, \" centrality\"), \\n',), ('        side = 4, line = 3)\\n',), ('  dev.off()\\n',), ('}\\n',), ('cent_plot(outdegree_avg, FRM_index$FRM)\\n',), ('cent_plot(indegree_avg, FRM_index$FRM)\\n',), ('cent_plot(betweenness_avg, FRM_index$FRM)\\n',), ('cent_plot(closeness_avg, FRM_index$FRM)\\n',), ('cent_plot(eigenvector_avg, FRM_index$FRM)\\n',)]\n"
     ]
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    print (batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = '\\n '.join([codeline[0].strip() for codeline in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tp = tokenized_batch.input_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_batch = tokenizer(bb, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5Model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5Model.from_pretrained(\"t5-small\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    ").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "# preprocess: Prepend decoder_input_ids with start token which is pad token for T5Model.\n",
    "# This is not needed for torch's T5ForConditionalGeneration as it does this internally using labels arg.\n",
    "decoder_input_ids = model._shift_right(decoder_input_ids)\n",
    "\n",
    "# forward pass\n",
    "outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "\n",
    "        tokenized_batch = tokenizer(bb, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_description_list = []\n",
    "for batch_idx, samples in tqdm(enumerate(data_loader)):\n",
    "      try:\n",
    "            nl_description = pipeline([codeline[0] for codeline in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tokenized_data = tokenizer(data, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[7089, 160, 3627, 1], [7089, 440, 3627, 1]], 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/zinovyee.hub/.local/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:921: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline = SummarizationPipeline(\n",
    "    model=AutoModelWithLMHead.from_pretrained(\"SEBIS/code_trans_t5_large_source_code_summarization_python_multitask\"),\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"SEBIS/code_trans_t5_large_source_code_summarization_python_multitask\",\n",
    "    skip_special_tokens=False),\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [01:15,  1.38it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "262it [05:07,  1.42it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "265it [05:09,  1.64it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "332it [07:08,  1.37s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "479it [09:25,  1.90it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "492it [09:35,  1.19it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "501it [09:43,  1.17it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "617it [11:51,  1.22s/it]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "732it [13:10,  1.42it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "734it [13:13,  1.12s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "767it [13:42,  2.06it/s]Your max_length is set to 20, but you input_length is only 7. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "778it [13:49,  1.45it/s]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "782it [13:52,  1.42it/s]Your max_length is set to 20, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "787it [13:55,  1.27it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "789it [13:56,  1.62it/s]Your max_length is set to 20, but you input_length is only 10. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "792it [13:58,  1.33it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "869it [15:14,  1.39it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "884it [15:30,  1.10s/it]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "898it [15:46,  1.15s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "915it [16:13,  1.08it/s]Your max_length is set to 20, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "960it [16:40,  1.49it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "978it [16:52,  1.46it/s]Your max_length is set to 20, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "980it [16:53,  1.48it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "984it [16:55,  1.75it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1005it [17:08,  1.70it/s]Your max_length is set to 20, but you input_length is only 10. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1010it [17:12,  1.34it/s]Your max_length is set to 20, but you input_length is only 9. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1015it [17:16,  1.21it/s]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1058it [18:01,  1.19it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1061it [18:02,  1.83it/s]Your max_length is set to 20, but you input_length is only 7. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1086it [18:24,  2.39s/it]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1089it [18:26,  1.21s/it]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1090it [18:26,  1.01s/it]Your max_length is set to 20, but you input_length is only 8. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1297it [23:15,  2.46s/it]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1335it [24:30,  1.33it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1515it [27:22,  1.14it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1516it [27:23,  1.23it/s]Your max_length is set to 20, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1521it [27:26,  1.28it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1626it [29:22,  1.20s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "1647it [29:42,  1.22s/it]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2185it [35:32,  1.40it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2371it [38:17,  1.48it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2450it [39:25,  1.41it/s]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2453it [39:27,  1.29it/s]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2454it [39:27,  1.71it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2639it [42:10,  1.62it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2640it [42:11,  1.63it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2647it [42:15,  1.52it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2648it [42:16,  1.77it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2669it [42:34,  1.04s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2792it [44:32,  1.28it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "2976it [47:03,  1.06it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3047it [48:32,  1.05s/it]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3071it [49:05,  1.03it/s]Your max_length is set to 20, but you input_length is only 9. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3078it [49:17,  1.71s/it]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3136it [50:42,  1.57it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3142it [50:52,  1.63s/it]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3147it [50:56,  1.08it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3160it [51:17,  2.17s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3162it [51:19,  1.72s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3165it [51:22,  1.20s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3168it [51:25,  1.29s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3171it [51:28,  1.07s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3289it [53:59,  2.22s/it]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3292it [54:05,  2.41s/it]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3307it [54:17,  1.08it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3309it [54:22,  1.92s/it]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3384it [55:41,  1.55it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3397it [55:49,  1.48it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3417it [56:05,  1.03it/s]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3421it [56:07,  1.33it/s]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3467it [56:49,  1.03it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3469it [56:50,  1.31it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3497it [57:11,  1.45it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3555it [58:16,  1.63s/it]Your max_length is set to 20, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3556it [58:17,  1.26s/it]Your max_length is set to 20, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3728it [1:02:03,  1.24it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3751it [1:02:22,  1.39it/s]Your max_length is set to 20, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3752it [1:02:23,  1.53it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3765it [1:02:34,  1.25it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3796it [1:03:15,  1.79s/it]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3807it [1:03:26,  1.43it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3813it [1:03:29,  1.61it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3856it [1:03:59,  1.29it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3863it [1:04:03,  1.50it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3868it [1:04:07,  1.54it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "3992it [1:06:06,  1.27it/s]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4121it [1:09:52,  1.01s/it]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4203it [1:10:59,  1.05s/it]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4238it [1:11:32,  1.50it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4281it [1:12:02,  1.46it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4284it [1:12:03,  1.89it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4294it [1:12:09,  1.50it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4295it [1:12:10,  1.88it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4297it [1:12:10,  2.18it/s]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4303it [1:12:14,  1.53it/s]Your max_length is set to 20, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4345it [1:12:54,  1.13s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4398it [1:13:35,  1.29it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4418it [1:13:51,  1.24it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4458it [1:14:17,  1.42it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4459it [1:14:17,  1.75it/s]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4461it [1:14:18,  1.72it/s]Your max_length is set to 20, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4507it [1:14:57,  1.17it/s]Your max_length is set to 20, but you input_length is only 7. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4534it [1:15:20,  1.30it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4595it [1:16:08,  1.31it/s]Your max_length is set to 20, but you input_length is only 7. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4752it [1:18:19,  1.19it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4842it [1:19:52,  1.17it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4846it [1:19:54,  1.58it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4847it [1:19:54,  1.86it/s]Your max_length is set to 20, but you input_length is only 10. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4860it [1:20:04,  1.20it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4864it [1:20:07,  1.20it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4875it [1:20:14,  1.66it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "4941it [1:21:05,  1.39it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5024it [1:22:14,  1.47it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5138it [1:23:37,  1.39it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5422it [1:27:55,  1.08s/it]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5425it [1:27:58,  1.11it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5480it [1:28:56,  1.25it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5569it [1:31:11,  1.09s/it]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5575it [1:31:30,  2.32s/it]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5593it [1:31:43,  1.24it/s]Your max_length is set to 20, but you input_length is only 8. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5597it [1:31:45,  1.39it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5600it [1:31:48,  1.22it/s]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5602it [1:31:49,  1.38it/s]Your max_length is set to 20, but you input_length is only 8. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5618it [1:32:00,  1.41it/s]Your max_length is set to 20, but you input_length is only 8. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5630it [1:32:27,  3.72s/it]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5640it [1:32:34,  1.42it/s]Your max_length is set to 20, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5651it [1:32:42,  1.33it/s]Your max_length is set to 20, but you input_length is only 8. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5663it [1:32:57,  1.12it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5672it [1:33:06,  1.30s/it]Your max_length is set to 20, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5673it [1:33:06,  1.03s/it]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5690it [1:33:48,  5.38s/it]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5691it [1:33:48,  3.97s/it]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5697it [1:33:52,  1.08s/it]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5778it [1:35:29,  1.23s/it]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5858it [1:37:00,  1.13it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5863it [1:37:03,  1.35it/s]Your max_length is set to 20, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5898it [1:37:29,  1.41it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5916it [1:37:44,  1.32it/s]Your max_length is set to 20, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "5974it [1:38:27,  1.33it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "6071it [1:39:39,  1.33it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "6103it [1:40:05,  1.28it/s]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "6104it [1:40:05,  1.68it/s]Your max_length is set to 20, but you input_length is only 2. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "6320it [1:46:24,  1.29it/s]Your max_length is set to 20, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "6332it [1:46:34,  1.15it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "6508it [1:49:38,  1.12s/it]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "6560it [1:50:23,  1.24it/s]Your max_length is set to 20, but you input_length is only 5. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7212it [2:00:29,  1.41it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7330it [2:02:29,  1.00it/s]Your max_length is set to 20, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7387it [2:03:20,  1.12it/s]Your max_length is set to 20, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7392it [2:03:23,  1.38it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7430it [2:04:02,  1.32it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7494it [2:04:56,  1.13it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7510it [2:05:08,  1.56it/s]Your max_length is set to 20, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7654it [2:07:30,  1.37it/s]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7665it [2:07:39,  1.35it/s]Your max_length is set to 20, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7852it [2:10:40,  1.26it/s]Your max_length is set to 20, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "7941it [2:12:08,  1.22it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "8001it [2:13:05,  1.49s/it]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "8050it [2:14:00,  1.02s/it]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "8241it [2:17:22,  1.24it/s]Your max_length is set to 20, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "8317it [2:18:23,  1.30s/it]Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "8350it [2:19:02,  1.05s/it]Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "8356it [2:19:07,  1.03it/s]Your max_length is set to 20, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "8379it [2:19:35,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "nl_description_list = []\n",
    "for batch_idx, samples in tqdm(enumerate(data_loader)):\n",
    "      try:\n",
    "            nl_description = pipeline([codeline[0] for codeline in samples])\n",
    "            if CLEAN_UP:\n",
    "                  nl_description = [re.sub(r'[^a-zA-Z0-9\\s]', '', summary['summary_text']) for summary in nl_description]\n",
    "                  nl_description = [re.sub(r'\\s+', ' ', summary).strip() for summary in nl_description]\n",
    "                  nl_description = [summary for summary in nl_description if len(summary) > 0]\n",
    "      except:\n",
    "            nl_description = []\n",
    "      nl_description_list.append({batch_idx : nl_description})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8379"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nl_description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr_Qs_file = '../../data/preprocessed/Quantlet/Descriptions_Qs_19032023.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(descr_Qs_file, 'wb') as f:\n",
    "        pickle.dump(nl_description_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encode_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
