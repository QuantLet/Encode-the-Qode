{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyyaml\n",
    "!pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/sorted/python/prepared'\n",
    "REPOS = os.listdir(PATH)\n",
    "DEV = True\n",
    "\n",
    "COLUMNS   = ['qname',\n",
    "            'Description',\n",
    "            'Sourcecode',\n",
    "            'Keywords',\n",
    "            'Author']\n",
    "\n",
    "\n",
    "if DEV: \n",
    "    f = 'DeepLearning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metainfo(path: str,\n",
    "                   columns: list) -> pd.DataFrame:\n",
    "    \n",
    "\n",
    "    Quantlet = pd.DataFrame(columns=columns, index=[0])\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        metainfo_file = yaml.safe_load(f)\n",
    "\n",
    "    for col in columns:\n",
    "        try: \n",
    "            if col=='qname': \n",
    "                qname = metainfo_file.get('Name of QuantLet', 'ERROR')\n",
    "                if qname=='ERROR':\n",
    "                    qname = metainfo_file.get('Name of Quantlet', 'ERROR')\n",
    "                Quantlet[col] = qname\n",
    "            elif col=='Sourcecode':\n",
    "                Quantlet.loc[0,col] = ['BEGINNING OF CODE']\n",
    "            else:\n",
    "                Quantlet[col] = metainfo_file[col]\n",
    "        except:\n",
    "            Quantlet[col] = 'ERROR'\n",
    "\n",
    "    return Quantlet\n",
    "\n",
    "\n",
    "def parse_quantlet(quantlet_name: str,\n",
    "                    path: str,\n",
    "                    columns: list) -> dict:\n",
    "    \"\"\"\n",
    "    DOCSTRING\n",
    "    \"\"\"\n",
    "    \n",
    "    QUANTLET_PATH = path + '/' + quantlet_name\n",
    "\n",
    "    FILES = os.listdir(QUANTLET_PATH)\n",
    "\n",
    "    metainfo_file = [s for s in FILES if (\"metainfo\" in s) or (\"Metainfo\" in s)  or (\"MetaInfo\" in s)][0]\n",
    "\n",
    "    META_PATH = QUANTLET_PATH + '/' + metainfo_file\n",
    "\n",
    "    Quantlet = parse_metainfo(META_PATH, \n",
    "                              columns)\n",
    "\n",
    "\n",
    "    for file_name in FILES:\n",
    "\n",
    "        if (\"metainfo\" in file_name) or  \\\n",
    "            (\"Metainfo\" in file_name) or \\\n",
    "            (\"MetaInfo\" in file_name) or \\\n",
    "             (\".DS_Store\" in file_name) or \\\n",
    "             (\".git\" in file_name) or \\\n",
    "             (\".Rhistory\" in file_name) or \\\n",
    "             (\".idea\" in file_name) or \\\n",
    "             (\".ipynb_checkpoints\" in file_name):  \n",
    "                continue\n",
    "\n",
    "        FILE_PATH = QUANTLET_PATH + '/' + file_name\n",
    "        \n",
    "        assert os.path.isfile(FILE_PATH)\n",
    "\n",
    "        if ('ipynb' in file_name):\n",
    "            os.popen(f\"jupyter nbconvert --to python {FILE_PATH}\")\n",
    "            file_name.replace('ipynb', 'py')\n",
    "\n",
    "        assert 'py' in file_name\n",
    "\n",
    "        with open(FILE_PATH, 'r') as f:\n",
    "            source_code = f.readlines()\n",
    "\n",
    "        Quantlet.loc[0,'Sourcecode'].append(source_code)\n",
    "\n",
    "    return Quantlet\n",
    "\n",
    "\n",
    "def quantlets_to_df(quantlet_list: list,\n",
    "                path: str,\n",
    "                columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    DOCSTRING\n",
    "    \"\"\" \n",
    "\n",
    "    quantlets_df = pd.DataFrame(\n",
    "                    #index=quantlet_list,\n",
    "                    columns=columns\n",
    "                    )\n",
    "    for quantlet in tqdm.tqdm(quantlet_list):\n",
    "        if '.DS_Store' in quantlet:\n",
    "            continue\n",
    "        parsed_q = parse_quantlet(quantlet,\n",
    "                                    path,\n",
    "                                    columns)\n",
    "        parsed_q['REPO_NAME'] = quantlet                                   \n",
    "        quantlets_df = pd.concat([quantlets_df, parsed_q], axis=0)\n",
    "        \n",
    "\n",
    "        \n",
    "    print('Parsing Finished')\n",
    "    return quantlets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = quantlets_to_df(REPOS,\n",
    "                PATH,\n",
    "                COLUMNS)\n",
    "df['code_scripts'] = df.Sourcecode.apply(lambda x: len(x) -1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/python_quantlets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5068c5f83f27504f643fbd77082c0ce556ae27ae78fa94fc3f8daafe95bc05c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('encode_code')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
